{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"papermill":{"duration":654.273766,"end_time":"2020-12-19T21:56:32.593054","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-12-19T21:45:38.319288","version":"2.1.0"},"colab":{"name":"transformer-baseline.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"13a0a25ba2744f4e8169996cfe4f0e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6ef6ce16979486eb09047eca2659196","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_307fa7f104864d65af9059adb6637a9f","IPY_MODEL_cd2c634868974bc882db5a42d96cdf5d"]}},"b6ef6ce16979486eb09047eca2659196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"307fa7f104864d65af9059adb6637a9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_460b039a60d54ba4b378ca7bb3aa54d1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1875000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1875000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1de71e769ef4e61be93f0a53bd77c54"}},"cd2c634868974bc882db5a42d96cdf5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b58971568904b048eaaafdd1fb73141","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1875000/1875000 [23:56&lt;00:00, 1304.83it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2d20c1190034d108e421155369f1bca"}},"460b039a60d54ba4b378ca7bb3aa54d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1de71e769ef4e61be93f0a53bd77c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b58971568904b048eaaafdd1fb73141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b2d20c1190034d108e421155369f1bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb68c79468504f14bcfdc6a85a16b2b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc783e6b050645908a56b3f3bc59e295","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a44dc431f4240ebb963b0b7434f7794","IPY_MODEL_b6a028a8cd734a049ee0ad5b726f0455"]}},"cc783e6b050645908a56b3f3bc59e295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a44dc431f4240ebb963b0b7434f7794":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4969c11082bb471e99a7adf6e0fdd491","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":9,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce850903f5a74485867622293c96fe42"}},"b6a028a8cd734a049ee0ad5b726f0455":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4999b4236da47e8b0e93a690b57ee2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9/9 [15:15&lt;00:00, 101.78s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce91da6b0f71438da4860ca1a4d94664"}},"4969c11082bb471e99a7adf6e0fdd491":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce850903f5a74485867622293c96fe42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4999b4236da47e8b0e93a690b57ee2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce91da6b0f71438da4860ca1a4d94664":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb4e67a35d904e06a15cfe3da02ba85d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_50fe860952f54712a15fcbfdf03e314f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a28c8d5f18348cfaa9a082cbee290fc","IPY_MODEL_00666d96d6f0492c97b6c8990dc2d134"]}},"50fe860952f54712a15fcbfdf03e314f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a28c8d5f18348cfaa9a082cbee290fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4daef016ec14f498abc0d04e73146d5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7fd19b1ac1e4e8b86d479050fa8f2ae"}},"00666d96d6f0492c97b6c8990dc2d134":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb299d3fe506465eb40b211abd99bd1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.65it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8709de796bf041e8812a2ef323d40e9c"}},"f4daef016ec14f498abc0d04e73146d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e7fd19b1ac1e4e8b86d479050fa8f2ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb299d3fe506465eb40b211abd99bd1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8709de796bf041e8812a2ef323d40e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69ab76bb417743f88049c020989acf79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6df59940cd342c0b238a10642f18f58","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fc1ae8716dc74fd18897781c36cf6e53","IPY_MODEL_77331773856043ee91c0b00437224339"]}},"b6df59940cd342c0b238a10642f18f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc1ae8716dc74fd18897781c36cf6e53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cc91ff975dda47f9b661cec2f1c45ccb","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c08e1180e53424ea15ac58c0a355c83"}},"77331773856043ee91c0b00437224339":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfbbc0d77ea34b6496bc349b4111db93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07b94aad2a7e4c75a7d05ab649e1ea8f"}},"cc91ff975dda47f9b661cec2f1c45ccb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3c08e1180e53424ea15ac58c0a355c83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfbbc0d77ea34b6496bc349b4111db93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07b94aad2a7e4c75a7d05ab649e1ea8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9024560e67f4d478bf99d5262cef382":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0517d1bff024064af00842db343e1d4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_083d3d85c0f646ad8579499f035b2fe9","IPY_MODEL_a504a0cb613e42b68709e55687096916"]}},"c0517d1bff024064af00842db343e1d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"083d3d85c0f646ad8579499f035b2fe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b77b1ce9da354401842dd13a54a58f75","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09b1ea1c8f3f44b6808ceac5034ae718"}},"a504a0cb613e42b68709e55687096916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c837a1f791f4aad927baa263e8f5049","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.66it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a40cf36bf60d4b2ba4c02f369f188f5d"}},"b77b1ce9da354401842dd13a54a58f75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09b1ea1c8f3f44b6808ceac5034ae718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c837a1f791f4aad927baa263e8f5049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a40cf36bf60d4b2ba4c02f369f188f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"812e2d6d03864e2cacb709c7ca553c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3004f7c0786f4081a868be7d5b71dbfb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2a7a123aee1840e6810b71ea6a4e8eec","IPY_MODEL_76d65cf11931463582a0e743196fd07e"]}},"3004f7c0786f4081a868be7d5b71dbfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a7a123aee1840e6810b71ea6a4e8eec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b2cc8d01abf4b6fbf7e271cbba2e447","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_904d577e69284ec1a0c7ec47cd0fe62e"}},"76d65cf11931463582a0e743196fd07e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb5b141910f640a9a077f76ca9cb67f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.56it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a09c2e0ba9714eb6a7897cc7b517f725"}},"3b2cc8d01abf4b6fbf7e271cbba2e447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"904d577e69284ec1a0c7ec47cd0fe62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb5b141910f640a9a077f76ca9cb67f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a09c2e0ba9714eb6a7897cc7b517f725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"629bb46197814b599177ffe1b53f29a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97ed707856b147ae9653094e699a92f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7b6c1e9a7f343f39b62dcce928ac776","IPY_MODEL_1e7d1eec48884a02affd0e5d44ffb2bc"]}},"97ed707856b147ae9653094e699a92f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7b6c1e9a7f343f39b62dcce928ac776":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b083c7767c4f4328b3c563d959942e26","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c9e2ef3d4154db28476f6ed06408506"}},"1e7d1eec48884a02affd0e5d44ffb2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c066e5447c64dd2aab5530641b23c8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.64it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_420a1be829a945d28cba697e9af8f366"}},"b083c7767c4f4328b3c563d959942e26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c9e2ef3d4154db28476f6ed06408506":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c066e5447c64dd2aab5530641b23c8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"420a1be829a945d28cba697e9af8f366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFBBlwXwJCOr","executionInfo":{"status":"ok","timestamp":1613461956983,"user_tz":-540,"elapsed":3170,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"bb54d410-7d5f-4ec5-caaa-cecf4c7ac8d2"},"source":["!pip install iterative-stratification"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.6/dist-packages (0.1.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.22.2.post1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (1.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_Pc0n7jwQSq","executionInfo":{"status":"ok","timestamp":1613461956983,"user_tz":-540,"elapsed":3163,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"65a8919e-0abf-4ee2-c40d-bd91e7cd6704"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7bJ70Ws1wSGD"},"source":["#경로 설정\r\n","import os\r\n","os.chdir('/content/drive/My Drive/Colab Notebooks/운동동작분류AI경진대회')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2020-12-19T21:45:42.915933Z","iopub.status.busy":"2020-12-19T21:45:42.915215Z","iopub.status.idle":"2020-12-19T21:45:55.422401Z","shell.execute_reply":"2020-12-19T21:45:55.423089Z"},"papermill":{"duration":12.539859,"end_time":"2020-12-19T21:45:55.423292","exception":false,"start_time":"2020-12-19T21:45:42.883433","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"9bbPFoUlwP3L","executionInfo":{"status":"ok","timestamp":1613461960425,"user_tz":-540,"elapsed":6597,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"279238f2-dcbd-49d5-9ca8-b04a513f0ae0"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import tensorflow as tf\n","tf.random.set_seed(42)\n","import tensorflow.keras.backend as K\n","import tensorflow.keras.layers as layers\n","from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","\n","import os, gc, random, datetime\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from sklearn.metrics import roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from joblib import dump, load\n","from time import time\n","import scipy as sp\n","import scipy.fftpack\n","\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","print(\"Tensorflow version \" + tf.__version__)\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensorflow version 2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.021446,"end_time":"2020-12-19T21:45:55.576052","exception":false,"start_time":"2020-12-19T21:45:55.554606","status":"completed"},"tags":[],"id":"dC9e5tXuwP3M"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"A77rJfaswP3M"},"source":["# 데이터 불러오기\n","\n","path = './data/'\n","train = pd.read_csv(path + 'train_features.csv')\n","train_label = pd.read_csv(path + 'train_labels.csv')\n","test = pd.read_csv(path + 'test_features.csv')\n","submission = pd.read_csv(path + 'sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4bg_yTDwP3M"},"source":["# Pre-Processing Effect on the Accuracy of Event-Based Activity Segmentation and Classification through Inertial Sensors \n","# https://www.researchgate.net/publication/281836367_Pre-Processing_Effect_on_the_Accuracy_of_Event-Based_Activity_Segmentation_and_Classification_through_Inertial_Sensors\n","\n","train['acc_t'] = train.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 + x['acc_z'] **2)**(1/2), axis=1)\n","test['acc_t'] = test.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 + x['acc_z'] **2)**(1/2), axis=1)\n","train['gy_t'] = train.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 + x['gy_z'] **2)**(1/2), axis=1)\n","test['gy_t'] = test.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 + x['gy_z'] **2)**(1/2), axis=1)\n","\n","# SVM selected features\n","train['mean'] = train[['acc_x','acc_y']].mean(axis=1)\n","train['median'] = train[['acc_y', 'gy_z', 'gy_t']].median(axis=1)\n","train['standard_deviation'] = train[['acc_x', 'acc_y']].std(axis=1)\n","train['interquartile'] = train.quantile(.75, axis=1) - train.quantile(.25, axis=1)\n","\n","\n","test['mean'] = test[['acc_x','acc_y']].mean(axis=1)\n","test['median'] = test[['acc_y', 'gy_z', 'gy_t']].median(axis=1)\n","test['standard_deviation'] = test[['acc_x', 'acc_y']].std(axis=1)\n","test['interquartile'] = test.quantile(.75, axis=1) - test.quantile(.25, axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHMRT0CZwP3N"},"source":["x = np.array(train.iloc[:,2:]).reshape(-1, 600, 12)\n","y = tf.keras.utils.to_categorical(train_label['label'])\n","test = np.array(test.iloc[:,2:]).reshape(-1, 600, 12)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XY0T8yquzpe"},"source":["## 도비님의 데이터 증강 방법"]},{"cell_type":"code","metadata":{"id":"ClQxLhFSuuIn"},"source":["# 26번을 제외한 id 리스트\r\n","feature = list(train_label[train_label['label'] != 26]['id'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["13a0a25ba2744f4e8169996cfe4f0e1c","b6ef6ce16979486eb09047eca2659196","307fa7f104864d65af9059adb6637a9f","cd2c634868974bc882db5a42d96cdf5d","460b039a60d54ba4b378ca7bb3aa54d1","e1de71e769ef4e61be93f0a53bd77c54","3b58971568904b048eaaafdd1fb73141","b2d20c1190034d108e421155369f1bca"]},"id":"0lkMdYWDu6eS","executionInfo":{"status":"ok","timestamp":1613462545698,"user_tz":-540,"elapsed":591852,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"f725bb4f-1208-4a4a-8a3f-4427058933b0"},"source":["# train 데이터에서 26번을 삭제시킨다.\r\n","temp = []\r\n","for n in tqdm(range(train.shape[0])):\r\n","    if train['id'][n] in feature:\r\n","        temp.append(train.iloc[n])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13a0a25ba2744f4e8169996cfe4f0e1c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1875000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnUHYQ1iu8E9"},"source":["# 26번을 삭제시킨 데이터프레임\r\n","without = pd.DataFrame(data=np.array(temp), columns=train.columns)\r\n","without = without.astype({'id':int, 'time':int})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKBjbqeDvCk9"},"source":["without_train = np.array(without.iloc[:,2:]).reshape(-1, 600, 12)\r\n","without_label = train_label[train_label['label'] != 26]['label']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["eb68c79468504f14bcfdc6a85a16b2b2","cc783e6b050645908a56b3f3bc59e295","8a44dc431f4240ebb963b0b7434f7794","b6a028a8cd734a049ee0ad5b726f0455","4969c11082bb471e99a7adf6e0fdd491","ce850903f5a74485867622293c96fe42","d4999b4236da47e8b0e93a690b57ee2e","ce91da6b0f71438da4860ca1a4d94664"]},"id":"6TigcFKFvU9f","executionInfo":{"status":"ok","timestamp":1613462565078,"user_tz":-540,"elapsed":611220,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"90c0e70c-2ad2-4be2-e032-6a57b3f496d5"},"source":["def aug(data, shift):\r\n","    shift_data = np.roll(data, shift, axis=1)\r\n","    return shift_data\r\n","\r\n","# 데이터 증강\r\n","shift_data = []\r\n","shift_label = []\r\n","for n in tqdm(range(1, 10)):\r\n","    shifted = aug(without_train, n*60)\r\n","    shift_data.append(shifted)\r\n","    shift_label.append(without_label)\r\n","\r\n","shift_data = np.array(shift_data).reshape(-1,600,12)\r\n","shift_label = np.array(shift_label).reshape(-1,1)\r\n","shift_categorical = tf.keras.utils.to_categorical(shift_label)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb68c79468504f14bcfdc6a85a16b2b2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLCjZo9rvU6t","executionInfo":{"status":"ok","timestamp":1613462565423,"user_tz":-540,"elapsed":611561,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"a5174fac-b28d-4076-9649-999c1621fbdb"},"source":["# 원본 데이터와 증강 데이터 합치기\r\n","concat_train = np.concatenate((x, shift_data), axis=0)\r\n","concat_label = np.concatenate((y, shift_categorical), axis=0)\r\n","print(concat_train.shape)\r\n","print(concat_label.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(17588, 600, 12)\n","(17588, 61)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uzqCgtG0e4j"},"source":["del x, shift_data, y, shift_categorical, without, without_train, without_label, feature, temp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.034259,"end_time":"2020-12-19T21:47:05.668897","exception":false,"start_time":"2020-12-19T21:47:05.634638","status":"completed"},"tags":[],"id":"ruDx0aTTwP3N"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.033446,"end_time":"2020-12-19T21:47:05.735558","exception":false,"start_time":"2020-12-19T21:47:05.702112","status":"completed"},"tags":[],"id":"jJCWdNkWwP3N"},"source":["Base Transformer structure from https://www.tensorflow.org/tutorials/text/transformer, modified with Swish activation function."]},{"cell_type":"code","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2020-12-19T21:47:05.822914Z","iopub.status.busy":"2020-12-19T21:47:05.821803Z","iopub.status.idle":"2020-12-19T21:47:05.866016Z","shell.execute_reply":"2020-12-19T21:47:05.865400Z"},"papermill":{"duration":0.09191,"end_time":"2020-12-19T21:47:05.866129","exception":false,"start_time":"2020-12-19T21:47:05.774219","status":"completed"},"tags":[],"id":"b7k4RMZhwP3N"},"source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"Calculate the attention weights.\n","    q, k, v must have matching leading dimensions.\n","    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","    The mask has different shapes depending on its type(padding or look ahead) \n","    but it must be broadcastable for addition.\n","\n","    Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","\n","    Returns:\n","    output, attention_weights\n","    \"\"\"\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b = True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        \n","        scaled_attention_logits += (mask * -1e9)  \n","\n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)  # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    \n","    def __init__(self, d_model, num_heads):\n","        \n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm = [0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        \n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention, \n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","        return output, attention_weights\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    \n","    return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation = 'relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    \n","    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n","        \n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training = training)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training = training)\n","        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        return out2\n","\n","class TransformerEncoder(tf.keras.layers.Layer):\n","    \n","    def __init__(self, num_layers, d_model, num_heads, dff, \n","                 maximum_position_encoding, rate = 0.1):\n","        \n","        super(TransformerEncoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.maximum_position_encoding = maximum_position_encoding\n","        self.rate = rate\n","\n","#         self.pos_encoding = positional_encoding(self.maximum_position_encoding, \n","#                                                 self.d_model)\n","#         self.embedding = tf.keras.layers.Dense(self.d_model)\n","        self.pos_emb = tf.keras.layers.Embedding(input_dim = self.maximum_position_encoding, \n","                                                 output_dim = self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(self.d_model, self.num_heads, self.dff, self.rate) \n","                           for _ in range(self.num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(self.rate)\n","        \n","    def get_config(self):\n","\n","        config = super().get_config().copy()\n","        config.update({\n","            'num_layers': self.num_layers,\n","            'd_model': self.d_model,\n","            'num_heads': self.num_heads,\n","            'dff': self.dff,\n","            'maximum_position_encoding': self.maximum_position_encoding,\n","            'dropout': self.dropout,\n","        })\n","        return config\n","\n","    def call(self, x, training, mask = None):\n","\n","        seq_len = tf.shape(x)[1]\n","\n","        # adding embedding and position encoding.\n","#         x += self.pos_encoding[:, :seq_len, :]\n","#         x = self.embedding(x)\n","        positions = tf.range(start = 0, limit = seq_len, delta = 1)\n","        x += self.pos_emb(positions)\n","\n","        x = self.dropout(x, training = training)\n","\n","        for i in range(self.num_layers):\n","\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x  # (batch_size, input_seq_len, d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:05.924111Z","iopub.status.busy":"2020-12-19T21:47:05.923351Z","iopub.status.idle":"2020-12-19T21:47:05.927506Z","shell.execute_reply":"2020-12-19T21:47:05.927026Z"},"papermill":{"duration":0.038039,"end_time":"2020-12-19T21:47:05.927604","exception":false,"start_time":"2020-12-19T21:47:05.889565","status":"completed"},"tags":[],"id":"mOCptCFxwP3P"},"source":["def create_transformer_model(num_columns, num_labels, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate):\n","    \n","    inp = tf.keras.layers.Input(shape = (window_size, num_columns))\n","    x = tf.keras.layers.BatchNormalization()(inp)\n","    x = tf.keras.layers.Dense(d_model)(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    x = tf.keras.layers.SpatialDropout1D(dropout_rate)(x)\n","    x = TransformerEncoder(num_layers, d_model, num_heads, dff, window_size, dropout_rate)(x)\n","    out = tf.keras.layers.Dense(num_labels, activation = 'softmax')(x[:, -1, :])\n","    \n","    model = tf.keras.models.Model(inputs = inp, outputs = out)\n","    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['AUC'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:06.026885Z","iopub.status.busy":"2020-12-19T21:47:06.025060Z","iopub.status.idle":"2020-12-19T21:47:06.027550Z","shell.execute_reply":"2020-12-19T21:47:06.028046Z"},"papermill":{"duration":0.031196,"end_time":"2020-12-19T21:47:06.028159","exception":false,"start_time":"2020-12-19T21:47:05.996963","status":"completed"},"tags":[],"id":"M8HPyemgwP3R"},"source":["batch_size = 32\n","num_layers = 1\n","d_model = 128\n","num_heads = 1\n","dff = 128\n","window_size = 600\n","dropout_rate = 0.15\n","weight_decay = 0\n","label_smoothing = 1e-2\n","learning_rate = 1e-3\n","verbose = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023272,"end_time":"2020-12-19T21:47:09.916436","exception":false,"start_time":"2020-12-19T21:47:09.893164","status":"completed"},"tags":[],"id":"CPgqEvivwP3R"},"source":["# Train-Test-Split Training\n","\n","Split the train set into three folds, i.e., training-1, training-2 and validation sets. First, train the more on training-1 set and validate it on the validation set. Then use the training-2 set to find the best number of finetuning epochs. Finally, finetune on both training-2 and validation sets and submit."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:12.495194Z","iopub.status.busy":"2020-12-19T21:47:12.494436Z","iopub.status.idle":"2020-12-19T21:48:42.358496Z","shell.execute_reply":"2020-12-19T21:48:42.357889Z"},"papermill":{"duration":89.899584,"end_time":"2020-12-19T21:48:42.358608","exception":false,"start_time":"2020-12-19T21:47:12.459024","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eb4e67a35d904e06a15cfe3da02ba85d","50fe860952f54712a15fcbfdf03e314f","8a28c8d5f18348cfaa9a082cbee290fc","00666d96d6f0492c97b6c8990dc2d134","f4daef016ec14f498abc0d04e73146d5","e7fd19b1ac1e4e8b86d479050fa8f2ae","eb299d3fe506465eb40b211abd99bd1e","8709de796bf041e8812a2ef323d40e9c","69ab76bb417743f88049c020989acf79","b6df59940cd342c0b238a10642f18f58","fc1ae8716dc74fd18897781c36cf6e53","77331773856043ee91c0b00437224339","cc91ff975dda47f9b661cec2f1c45ccb","3c08e1180e53424ea15ac58c0a355c83","cfbbc0d77ea34b6496bc349b4111db93","07b94aad2a7e4c75a7d05ab649e1ea8f","d9024560e67f4d478bf99d5262cef382","c0517d1bff024064af00842db343e1d4","083d3d85c0f646ad8579499f035b2fe9","a504a0cb613e42b68709e55687096916","b77b1ce9da354401842dd13a54a58f75","09b1ea1c8f3f44b6808ceac5034ae718","4c837a1f791f4aad927baa263e8f5049","a40cf36bf60d4b2ba4c02f369f188f5d","812e2d6d03864e2cacb709c7ca553c64","3004f7c0786f4081a868be7d5b71dbfb","2a7a123aee1840e6810b71ea6a4e8eec","76d65cf11931463582a0e743196fd07e","3b2cc8d01abf4b6fbf7e271cbba2e447","904d577e69284ec1a0c7ec47cd0fe62e","eb5b141910f640a9a077f76ca9cb67f8","a09c2e0ba9714eb6a7897cc7b517f725","629bb46197814b599177ffe1b53f29a1","97ed707856b147ae9653094e699a92f7","e7b6c1e9a7f343f39b62dcce928ac776","1e7d1eec48884a02affd0e5d44ffb2bc","b083c7767c4f4328b3c563d959942e26","2c9e2ef3d4154db28476f6ed06408506","3c066e5447c64dd2aab5530641b23c8e","420a1be829a945d28cba697e9af8f366"]},"id":"q5wj-CmawP3R","executionInfo":{"status":"ok","timestamp":1613471395300,"user_tz":-540,"elapsed":4281529,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"d98f4329-35d6-4d1d-ac96-a2f4aed0f536"},"source":["# 모델 1번: Transformer\n","\n","def build_transformer(split_num, train, target, test, rnd):\n","    start_time_fold = time()\n","    # return train pred prob and test pred prob \n","    test_pred, shifted_test_pred = np.zeros((test.shape[0], 61)), np.zeros((test.shape[0], 61))\n","\n","    ckp_path = 'transformer.hdf5'\n","\n","    rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = verbose, min_delta = 1e-4, mode = 'min')\n","    ckp = ModelCheckpoint(ckp_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n","    es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 4, mode = 'min', baseline = None, restore_best_weights = True, verbose = 0)\n","\n","    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    for train_idx, val_idx in mskf.split(train, target):\n","\n","        # split train, validation set\n","        X = train[train_idx]\n","        y = target[train_idx]\n","        valid_x = train[val_idx]\n","        valid_y = target[val_idx]\n","\n","        #가벼운 모델 생성\n","        model = create_transformer_model(train.shape[2], 61, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\n","\n","        model.fit(X, y, epochs = 100,\n","                  validation_data = (valid_x, valid_y),\n","                  batch_size = batch_size,\n","                  callbacks = [rlr, ckp, es],\n","                  verbose = verbose)\n","        \n","        # save feat\n","        model.load_weights(ckp_path)\n","        test_pred += model.predict(test)/(split_num)\n","\n","        # 테스트 데이터 증강\n","        shift_test = []\n","        for n in tqdm(range(10)):\n","            shifted = aug(test, n*60)\n","            shifted_test_pred += model.predict(shifted)/(split_num*10)\n","        \n","        # release\n","        del model\n","        gc.collect()\n","        print('  ==============================================================================================  ')\n","\n","        \n","    return test_pred, shifted_test_pred\n","\n","transformer_test, transformer_test_shifted = build_transformer(5, concat_train, concat_label, test, 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","440/440 [==============================] - 15s 30ms/step - loss: 3.1127 - auc: 0.8338 - val_loss: 1.7794 - val_auc: 0.9600\n","Epoch 2/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.9249 - auc: 0.9562 - val_loss: 1.3764 - val_auc: 0.9763\n","Epoch 3/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.6059 - auc: 0.9694 - val_loss: 1.2295 - val_auc: 0.9801\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4120 - auc: 0.9758 - val_loss: 1.0556 - val_auc: 0.9849\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2631 - auc: 0.9808 - val_loss: 0.9872 - val_auc: 0.9873\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2017 - auc: 0.9825 - val_loss: 0.8578 - val_auc: 0.9915\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1077 - auc: 0.9845 - val_loss: 0.8202 - val_auc: 0.9914\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0421 - auc: 0.9869 - val_loss: 0.7643 - val_auc: 0.9924\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9844 - auc: 0.9884 - val_loss: 0.6972 - val_auc: 0.9933\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9507 - auc: 0.9887 - val_loss: 0.6821 - val_auc: 0.9938\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8664 - auc: 0.9908 - val_loss: 0.6301 - val_auc: 0.9951\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8388 - auc: 0.9916 - val_loss: 0.6199 - val_auc: 0.9943\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8374 - auc: 0.9908 - val_loss: 0.5818 - val_auc: 0.9955\n","Epoch 14/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7775 - auc: 0.9921 - val_loss: 0.5590 - val_auc: 0.9952\n","Epoch 15/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7429 - auc: 0.9926 - val_loss: 0.5157 - val_auc: 0.9960\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7369 - auc: 0.9932 - val_loss: 0.5166 - val_auc: 0.9963\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7196 - auc: 0.9933 - val_loss: 0.4904 - val_auc: 0.9967\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6969 - auc: 0.9939 - val_loss: 0.4815 - val_auc: 0.9966\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6876 - auc: 0.9932 - val_loss: 0.4389 - val_auc: 0.9974\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6504 - auc: 0.9946 - val_loss: 0.4189 - val_auc: 0.9972\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6326 - auc: 0.9941 - val_loss: 0.4290 - val_auc: 0.9970\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6268 - auc: 0.9940 - val_loss: 0.3881 - val_auc: 0.9979\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6028 - auc: 0.9949 - val_loss: 0.3613 - val_auc: 0.9978\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6168 - auc: 0.9945 - val_loss: 0.3500 - val_auc: 0.9978\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5627 - auc: 0.9947 - val_loss: 0.3840 - val_auc: 0.9977\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5655 - auc: 0.9955 - val_loss: 0.3563 - val_auc: 0.9985\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5765 - auc: 0.9951 - val_loss: 0.3349 - val_auc: 0.9984\n","Epoch 28/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5443 - auc: 0.9948 - val_loss: 0.3612 - val_auc: 0.9977\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5314 - auc: 0.9957 - val_loss: 0.3431 - val_auc: 0.9986\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5367 - auc: 0.9952 - val_loss: 0.3116 - val_auc: 0.9988\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5091 - auc: 0.9958 - val_loss: 0.3004 - val_auc: 0.9986\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5181 - auc: 0.9960 - val_loss: 0.2984 - val_auc: 0.9986\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5151 - auc: 0.9953 - val_loss: 0.2961 - val_auc: 0.9982\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5226 - auc: 0.9950 - val_loss: 0.2999 - val_auc: 0.9984\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4739 - auc: 0.9960 - val_loss: 0.3015 - val_auc: 0.9987\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4977 - auc: 0.9953 - val_loss: 0.3238 - val_auc: 0.9979\n","\n","Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 37/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4469 - auc: 0.9969 - val_loss: 0.2359 - val_auc: 0.9990\n","Epoch 38/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3699 - auc: 0.9977 - val_loss: 0.2260 - val_auc: 0.9990\n","Epoch 39/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3560 - auc: 0.9978 - val_loss: 0.2151 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3556 - auc: 0.9984 - val_loss: 0.2118 - val_auc: 0.9994\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3510 - auc: 0.9980 - val_loss: 0.2082 - val_auc: 0.9992\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3319 - auc: 0.9985 - val_loss: 0.2085 - val_auc: 0.9994\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3246 - auc: 0.9984 - val_loss: 0.2038 - val_auc: 0.9990\n","Epoch 44/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3360 - auc: 0.9982 - val_loss: 0.2044 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3330 - auc: 0.9986 - val_loss: 0.2057 - val_auc: 0.9990\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3276 - auc: 0.9981 - val_loss: 0.2004 - val_auc: 0.9991\n","Epoch 47/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3222 - auc: 0.9980 - val_loss: 0.1983 - val_auc: 0.9990\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3164 - auc: 0.9985 - val_loss: 0.1912 - val_auc: 0.9992\n","Epoch 49/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3117 - auc: 0.9986 - val_loss: 0.1991 - val_auc: 0.9990\n","Epoch 50/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3208 - auc: 0.9978 - val_loss: 0.1922 - val_auc: 0.9993\n","Epoch 51/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3190 - auc: 0.9985 - val_loss: 0.1892 - val_auc: 0.9991\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3309 - auc: 0.9982 - val_loss: 0.1873 - val_auc: 0.9992\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3213 - auc: 0.9982 - val_loss: 0.1876 - val_auc: 0.9992\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3192 - auc: 0.9983 - val_loss: 0.1854 - val_auc: 0.9990\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3068 - auc: 0.9985 - val_loss: 0.1825 - val_auc: 0.9992\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3091 - auc: 0.9983 - val_loss: 0.1806 - val_auc: 0.9990\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2987 - auc: 0.9986 - val_loss: 0.1813 - val_auc: 0.9992\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3091 - auc: 0.9982 - val_loss: 0.1811 - val_auc: 0.9990\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2979 - auc: 0.9981 - val_loss: 0.1834 - val_auc: 0.9992\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 60/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3024 - auc: 0.9985 - val_loss: 0.1795 - val_auc: 0.9992\n","Epoch 61/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3008 - auc: 0.9987 - val_loss: 0.1789 - val_auc: 0.9992\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2882 - auc: 0.9983 - val_loss: 0.1764 - val_auc: 0.9992\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2749 - auc: 0.9987 - val_loss: 0.1767 - val_auc: 0.9992\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2867 - auc: 0.9983 - val_loss: 0.1765 - val_auc: 0.9992\n","Epoch 65/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2910 - auc: 0.9984 - val_loss: 0.1748 - val_auc: 0.9992\n","Epoch 66/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2981 - auc: 0.9985 - val_loss: 0.1749 - val_auc: 0.9992\n","Epoch 67/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2913 - auc: 0.9982 - val_loss: 0.1762 - val_auc: 0.9992\n","Epoch 68/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2861 - auc: 0.9987 - val_loss: 0.1761 - val_auc: 0.9992\n","\n","Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 69/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2807 - auc: 0.9986 - val_loss: 0.1743 - val_auc: 0.9992\n","Epoch 70/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2867 - auc: 0.9984 - val_loss: 0.1739 - val_auc: 0.9992\n","Epoch 71/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2770 - auc: 0.9986 - val_loss: 0.1747 - val_auc: 0.9992\n","Epoch 72/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3176 - auc: 0.9983 - val_loss: 0.1747 - val_auc: 0.9992\n","Epoch 73/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2881 - auc: 0.9983 - val_loss: 0.1759 - val_auc: 0.9992\n","\n","Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 74/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2874 - auc: 0.9984 - val_loss: 0.1740 - val_auc: 0.9992\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb4e67a35d904e06a15cfe3da02ba85d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.1020 - auc: 0.8366 - val_loss: 1.8115 - val_auc: 0.9630\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 2.0098 - auc: 0.9511 - val_loss: 1.3679 - val_auc: 0.9775\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6392 - auc: 0.9679 - val_loss: 1.1351 - val_auc: 0.9836\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4521 - auc: 0.9723 - val_loss: 0.9991 - val_auc: 0.9881\n","Epoch 5/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.3102 - auc: 0.9784 - val_loss: 0.9621 - val_auc: 0.9881\n","Epoch 6/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1943 - auc: 0.9825 - val_loss: 0.8560 - val_auc: 0.9906\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1052 - auc: 0.9847 - val_loss: 0.8334 - val_auc: 0.9911\n","Epoch 8/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.0470 - auc: 0.9865 - val_loss: 0.7293 - val_auc: 0.9933\n","Epoch 9/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9775 - auc: 0.9895 - val_loss: 0.6871 - val_auc: 0.9948\n","Epoch 10/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9339 - auc: 0.9890 - val_loss: 0.6919 - val_auc: 0.9937\n","Epoch 11/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9070 - auc: 0.9895 - val_loss: 0.6386 - val_auc: 0.9944\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8762 - auc: 0.9907 - val_loss: 0.6075 - val_auc: 0.9947\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8147 - auc: 0.9917 - val_loss: 0.6001 - val_auc: 0.9950\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8050 - auc: 0.9916 - val_loss: 0.5833 - val_auc: 0.9949\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7590 - auc: 0.9926 - val_loss: 0.5426 - val_auc: 0.9953\n","Epoch 16/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7204 - auc: 0.9930 - val_loss: 0.5311 - val_auc: 0.9963\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7397 - auc: 0.9933 - val_loss: 0.5381 - val_auc: 0.9971\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6993 - auc: 0.9930 - val_loss: 0.4994 - val_auc: 0.9970\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6861 - auc: 0.9936 - val_loss: 0.4728 - val_auc: 0.9967\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6645 - auc: 0.9940 - val_loss: 0.4662 - val_auc: 0.9970\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6630 - auc: 0.9940 - val_loss: 0.4368 - val_auc: 0.9972\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6293 - auc: 0.9941 - val_loss: 0.4349 - val_auc: 0.9972\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6558 - auc: 0.9936 - val_loss: 0.4097 - val_auc: 0.9971\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5832 - auc: 0.9956 - val_loss: 0.4037 - val_auc: 0.9971\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5720 - auc: 0.9955 - val_loss: 0.3836 - val_auc: 0.9977\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5797 - auc: 0.9945 - val_loss: 0.3662 - val_auc: 0.9975\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5699 - auc: 0.9949 - val_loss: 0.3735 - val_auc: 0.9975\n","Epoch 28/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5460 - auc: 0.9951 - val_loss: 0.3616 - val_auc: 0.9975\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5364 - auc: 0.9954 - val_loss: 0.3642 - val_auc: 0.9979\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5691 - auc: 0.9944 - val_loss: 0.3351 - val_auc: 0.9984\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5349 - auc: 0.9953 - val_loss: 0.3285 - val_auc: 0.9979\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4992 - auc: 0.9959 - val_loss: 0.3589 - val_auc: 0.9977\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4922 - auc: 0.9958 - val_loss: 0.3472 - val_auc: 0.9973\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5199 - auc: 0.9948 - val_loss: 0.3298 - val_auc: 0.9972\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4472 - auc: 0.9961 - val_loss: 0.2548 - val_auc: 0.9982\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3823 - auc: 0.9975 - val_loss: 0.2461 - val_auc: 0.9984\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3782 - auc: 0.9978 - val_loss: 0.2381 - val_auc: 0.9983\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3679 - auc: 0.9981 - val_loss: 0.2410 - val_auc: 0.9983\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3672 - auc: 0.9978 - val_loss: 0.2310 - val_auc: 0.9985\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3547 - auc: 0.9980 - val_loss: 0.2269 - val_auc: 0.9983\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3518 - auc: 0.9979 - val_loss: 0.2256 - val_auc: 0.9986\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3480 - auc: 0.9981 - val_loss: 0.2212 - val_auc: 0.9984\n","Epoch 43/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3470 - auc: 0.9982 - val_loss: 0.2187 - val_auc: 0.9986\n","Epoch 44/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3587 - auc: 0.9976 - val_loss: 0.2159 - val_auc: 0.9985\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3350 - auc: 0.9980 - val_loss: 0.2200 - val_auc: 0.9984\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3399 - auc: 0.9977 - val_loss: 0.2181 - val_auc: 0.9984\n","Epoch 47/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3428 - auc: 0.9980 - val_loss: 0.2156 - val_auc: 0.9982\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3324 - auc: 0.9977 - val_loss: 0.2131 - val_auc: 0.9984\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3269 - auc: 0.9978 - val_loss: 0.2094 - val_auc: 0.9985\n","Epoch 50/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3355 - auc: 0.9982 - val_loss: 0.2034 - val_auc: 0.9985\n","Epoch 51/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3066 - auc: 0.9986 - val_loss: 0.2044 - val_auc: 0.9987\n","Epoch 52/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3248 - auc: 0.9983 - val_loss: 0.2076 - val_auc: 0.9984\n","Epoch 53/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3271 - auc: 0.9984 - val_loss: 0.2053 - val_auc: 0.9984\n","\n","Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 54/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3205 - auc: 0.9977 - val_loss: 0.2010 - val_auc: 0.9986\n","Epoch 55/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3086 - auc: 0.9987 - val_loss: 0.2012 - val_auc: 0.9986\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3096 - auc: 0.9984 - val_loss: 0.1986 - val_auc: 0.9986\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3050 - auc: 0.9984 - val_loss: 0.1986 - val_auc: 0.9987\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3316 - auc: 0.9984 - val_loss: 0.1990 - val_auc: 0.9986\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3066 - auc: 0.9988 - val_loss: 0.2021 - val_auc: 0.9985\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 60/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3246 - auc: 0.9981 - val_loss: 0.1995 - val_auc: 0.9986\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69ab76bb417743f88049c020989acf79","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.0901 - auc: 0.8367 - val_loss: 1.8356 - val_auc: 0.9588\n","Epoch 2/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.9623 - auc: 0.9533 - val_loss: 1.3354 - val_auc: 0.9780\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6016 - auc: 0.9672 - val_loss: 1.1802 - val_auc: 0.9827\n","Epoch 4/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.4118 - auc: 0.9750 - val_loss: 1.0491 - val_auc: 0.9871\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.3130 - auc: 0.9796 - val_loss: 1.0026 - val_auc: 0.9868\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1739 - auc: 0.9831 - val_loss: 0.8699 - val_auc: 0.9895\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1014 - auc: 0.9850 - val_loss: 0.8397 - val_auc: 0.9911\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0627 - auc: 0.9851 - val_loss: 0.7676 - val_auc: 0.9927\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9764 - auc: 0.9888 - val_loss: 0.7469 - val_auc: 0.9928\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9318 - auc: 0.9891 - val_loss: 0.7061 - val_auc: 0.9935\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8947 - auc: 0.9895 - val_loss: 0.6543 - val_auc: 0.9945\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8692 - auc: 0.9910 - val_loss: 0.6336 - val_auc: 0.9944\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8189 - auc: 0.9916 - val_loss: 0.5891 - val_auc: 0.9952\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8077 - auc: 0.9916 - val_loss: 0.5791 - val_auc: 0.9955\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7781 - auc: 0.9921 - val_loss: 0.5484 - val_auc: 0.9962\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7412 - auc: 0.9928 - val_loss: 0.5151 - val_auc: 0.9965\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7202 - auc: 0.9929 - val_loss: 0.5344 - val_auc: 0.9965\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6713 - auc: 0.9942 - val_loss: 0.5005 - val_auc: 0.9961\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6860 - auc: 0.9935 - val_loss: 0.4699 - val_auc: 0.9965\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6544 - auc: 0.9947 - val_loss: 0.4588 - val_auc: 0.9974\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6369 - auc: 0.9943 - val_loss: 0.4537 - val_auc: 0.9969\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6093 - auc: 0.9951 - val_loss: 0.4305 - val_auc: 0.9976\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6074 - auc: 0.9950 - val_loss: 0.4260 - val_auc: 0.9969\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6141 - auc: 0.9939 - val_loss: 0.3978 - val_auc: 0.9984\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5955 - auc: 0.9949 - val_loss: 0.3686 - val_auc: 0.9986\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5774 - auc: 0.9952 - val_loss: 0.3772 - val_auc: 0.9980\n","Epoch 27/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5639 - auc: 0.9950 - val_loss: 0.3507 - val_auc: 0.9987\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5509 - auc: 0.9954 - val_loss: 0.3447 - val_auc: 0.9977\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5068 - auc: 0.9957 - val_loss: 0.3618 - val_auc: 0.9985\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5479 - auc: 0.9949 - val_loss: 0.3652 - val_auc: 0.9979\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5136 - auc: 0.9955 - val_loss: 0.3277 - val_auc: 0.9981\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5178 - auc: 0.9959 - val_loss: 0.2970 - val_auc: 0.9987\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5028 - auc: 0.9963 - val_loss: 0.3199 - val_auc: 0.9984\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4834 - auc: 0.9966 - val_loss: 0.3177 - val_auc: 0.9982\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5038 - auc: 0.9950 - val_loss: 0.2974 - val_auc: 0.9990\n","\n","Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4024 - auc: 0.9977 - val_loss: 0.2404 - val_auc: 0.9991\n","Epoch 37/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3665 - auc: 0.9982 - val_loss: 0.2337 - val_auc: 0.9991\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3747 - auc: 0.9978 - val_loss: 0.2292 - val_auc: 0.9993\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3644 - auc: 0.9982 - val_loss: 0.2250 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3654 - auc: 0.9982 - val_loss: 0.2250 - val_auc: 0.9992\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3464 - auc: 0.9981 - val_loss: 0.2208 - val_auc: 0.9990\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3560 - auc: 0.9982 - val_loss: 0.2101 - val_auc: 0.9995\n","Epoch 43/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3411 - auc: 0.9985 - val_loss: 0.2089 - val_auc: 0.9994\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3394 - auc: 0.9981 - val_loss: 0.2114 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3441 - auc: 0.9980 - val_loss: 0.2047 - val_auc: 0.9992\n","Epoch 46/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3263 - auc: 0.9984 - val_loss: 0.2051 - val_auc: 0.9992\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3344 - auc: 0.9980 - val_loss: 0.2035 - val_auc: 0.9991\n","Epoch 48/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3319 - auc: 0.9979 - val_loss: 0.2020 - val_auc: 0.9991\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3268 - auc: 0.9985 - val_loss: 0.1980 - val_auc: 0.9991\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3290 - auc: 0.9980 - val_loss: 0.1960 - val_auc: 0.9991\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3130 - auc: 0.9984 - val_loss: 0.1983 - val_auc: 0.9992\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3288 - auc: 0.9984 - val_loss: 0.1949 - val_auc: 0.9993\n","Epoch 53/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3333 - auc: 0.9980 - val_loss: 0.1967 - val_auc: 0.9991\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3151 - auc: 0.9980 - val_loss: 0.1901 - val_auc: 0.9995\n","Epoch 55/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3141 - auc: 0.9986 - val_loss: 0.1877 - val_auc: 0.9996\n","Epoch 56/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3040 - auc: 0.9985 - val_loss: 0.1917 - val_auc: 0.9993\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3117 - auc: 0.9981 - val_loss: 0.1885 - val_auc: 0.9991\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3112 - auc: 0.9984 - val_loss: 0.1860 - val_auc: 0.9991\n","Epoch 59/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3132 - auc: 0.9982 - val_loss: 0.1877 - val_auc: 0.9993\n","Epoch 60/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3056 - auc: 0.9984 - val_loss: 0.1868 - val_auc: 0.9993\n","Epoch 61/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3158 - auc: 0.9983 - val_loss: 0.1848 - val_auc: 0.9991\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2997 - auc: 0.9984 - val_loss: 0.1815 - val_auc: 0.9992\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3119 - auc: 0.9984 - val_loss: 0.1822 - val_auc: 0.9990\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2931 - auc: 0.9988 - val_loss: 0.1798 - val_auc: 0.9992\n","Epoch 65/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3058 - auc: 0.9980 - val_loss: 0.1807 - val_auc: 0.9990\n","Epoch 66/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3022 - auc: 0.9985 - val_loss: 0.1763 - val_auc: 0.9992\n","Epoch 67/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2958 - auc: 0.9980 - val_loss: 0.1758 - val_auc: 0.9992\n","Epoch 68/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3106 - auc: 0.9983 - val_loss: 0.1798 - val_auc: 0.9989\n","Epoch 69/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2986 - auc: 0.9979 - val_loss: 0.1733 - val_auc: 0.9990\n","Epoch 70/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2934 - auc: 0.9986 - val_loss: 0.1814 - val_auc: 0.9990\n","Epoch 71/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2905 - auc: 0.9984 - val_loss: 0.1794 - val_auc: 0.9990\n","Epoch 72/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2955 - auc: 0.9982 - val_loss: 0.1751 - val_auc: 0.9990\n","\n","Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 73/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2914 - auc: 0.9985 - val_loss: 0.1734 - val_auc: 0.9990\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9024560e67f4d478bf99d5262cef382","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 30ms/step - loss: 3.0787 - auc: 0.8417 - val_loss: 1.8675 - val_auc: 0.9584\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.9414 - auc: 0.9559 - val_loss: 1.3733 - val_auc: 0.9761\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6113 - auc: 0.9683 - val_loss: 1.1937 - val_auc: 0.9812\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.3836 - auc: 0.9755 - val_loss: 1.0156 - val_auc: 0.9866\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2843 - auc: 0.9789 - val_loss: 0.9422 - val_auc: 0.9884\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1670 - auc: 0.9829 - val_loss: 0.8551 - val_auc: 0.9906\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1119 - auc: 0.9838 - val_loss: 0.7707 - val_auc: 0.9910\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0584 - auc: 0.9861 - val_loss: 0.7205 - val_auc: 0.9928\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9618 - auc: 0.9888 - val_loss: 0.6970 - val_auc: 0.9936\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9140 - auc: 0.9895 - val_loss: 0.6432 - val_auc: 0.9944\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8811 - auc: 0.9904 - val_loss: 0.6155 - val_auc: 0.9958\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8457 - auc: 0.9904 - val_loss: 0.5483 - val_auc: 0.9961\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7702 - auc: 0.9922 - val_loss: 0.5629 - val_auc: 0.9958\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7561 - auc: 0.9923 - val_loss: 0.5075 - val_auc: 0.9970\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7613 - auc: 0.9928 - val_loss: 0.5237 - val_auc: 0.9972\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6991 - auc: 0.9939 - val_loss: 0.4595 - val_auc: 0.9976\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6879 - auc: 0.9938 - val_loss: 0.4561 - val_auc: 0.9976\n","Epoch 18/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7001 - auc: 0.9939 - val_loss: 0.4440 - val_auc: 0.9976\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6485 - auc: 0.9944 - val_loss: 0.4102 - val_auc: 0.9977\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6740 - auc: 0.9930 - val_loss: 0.3994 - val_auc: 0.9979\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6294 - auc: 0.9943 - val_loss: 0.4076 - val_auc: 0.9979\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6229 - auc: 0.9941 - val_loss: 0.3736 - val_auc: 0.9982\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5816 - auc: 0.9948 - val_loss: 0.3676 - val_auc: 0.9974\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5883 - auc: 0.9945 - val_loss: 0.3391 - val_auc: 0.9981\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5821 - auc: 0.9952 - val_loss: 0.3619 - val_auc: 0.9982\n","Epoch 26/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5587 - auc: 0.9952 - val_loss: 0.3456 - val_auc: 0.9981\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5640 - auc: 0.9952 - val_loss: 0.3446 - val_auc: 0.9984\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5043 - auc: 0.9963 - val_loss: 0.2566 - val_auc: 0.9991\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4375 - auc: 0.9973 - val_loss: 0.2509 - val_auc: 0.9991\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4147 - auc: 0.9977 - val_loss: 0.2452 - val_auc: 0.9991\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3989 - auc: 0.9978 - val_loss: 0.2354 - val_auc: 0.9992\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4163 - auc: 0.9976 - val_loss: 0.2377 - val_auc: 0.9992\n","Epoch 33/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3972 - auc: 0.9980 - val_loss: 0.2317 - val_auc: 0.9992\n","Epoch 34/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4155 - auc: 0.9971 - val_loss: 0.2274 - val_auc: 0.9992\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3869 - auc: 0.9980 - val_loss: 0.2238 - val_auc: 0.9992\n","Epoch 36/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3846 - auc: 0.9979 - val_loss: 0.2235 - val_auc: 0.9992\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4052 - auc: 0.9975 - val_loss: 0.2192 - val_auc: 0.9992\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3830 - auc: 0.9975 - val_loss: 0.2147 - val_auc: 0.9992\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3844 - auc: 0.9977 - val_loss: 0.2149 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3739 - auc: 0.9978 - val_loss: 0.2138 - val_auc: 0.9992\n","Epoch 41/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3744 - auc: 0.9981 - val_loss: 0.2076 - val_auc: 0.9993\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3765 - auc: 0.9976 - val_loss: 0.2068 - val_auc: 0.9993\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3667 - auc: 0.9977 - val_loss: 0.2041 - val_auc: 0.9991\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3632 - auc: 0.9979 - val_loss: 0.2117 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3786 - auc: 0.9975 - val_loss: 0.2037 - val_auc: 0.9993\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3602 - auc: 0.9978 - val_loss: 0.2026 - val_auc: 0.9993\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3575 - auc: 0.9981 - val_loss: 0.2100 - val_auc: 0.9992\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3570 - auc: 0.9981 - val_loss: 0.2008 - val_auc: 0.9991\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3719 - auc: 0.9970 - val_loss: 0.1952 - val_auc: 0.9993\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3558 - auc: 0.9980 - val_loss: 0.1967 - val_auc: 0.9993\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3664 - auc: 0.9977 - val_loss: 0.1964 - val_auc: 0.9991\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3368 - auc: 0.9981 - val_loss: 0.1969 - val_auc: 0.9993\n","\n","Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3496 - auc: 0.9980 - val_loss: 0.1932 - val_auc: 0.9993\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3436 - auc: 0.9979 - val_loss: 0.1928 - val_auc: 0.9993\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3477 - auc: 0.9983 - val_loss: 0.1914 - val_auc: 0.9993\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3384 - auc: 0.9980 - val_loss: 0.1906 - val_auc: 0.9993\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3547 - auc: 0.9976 - val_loss: 0.1901 - val_auc: 0.9993\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3458 - auc: 0.9981 - val_loss: 0.1911 - val_auc: 0.9993\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3496 - auc: 0.9982 - val_loss: 0.1886 - val_auc: 0.9993\n","Epoch 60/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3503 - auc: 0.9977 - val_loss: 0.1878 - val_auc: 0.9993\n","Epoch 61/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3567 - auc: 0.9980 - val_loss: 0.1883 - val_auc: 0.9993\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3229 - auc: 0.9983 - val_loss: 0.1888 - val_auc: 0.9993\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3374 - auc: 0.9981 - val_loss: 0.1879 - val_auc: 0.9993\n","\n","Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3424 - auc: 0.9981 - val_loss: 0.1880 - val_auc: 0.9993\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"812e2d6d03864e2cacb709c7ca553c64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.0140 - auc: 0.8486 - val_loss: 1.7700 - val_auc: 0.9623\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.9675 - auc: 0.9528 - val_loss: 1.3447 - val_auc: 0.9810\n","Epoch 3/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.5591 - auc: 0.9697 - val_loss: 1.1718 - val_auc: 0.9832\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4104 - auc: 0.9771 - val_loss: 1.0134 - val_auc: 0.9890\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2923 - auc: 0.9796 - val_loss: 0.9371 - val_auc: 0.9891\n","Epoch 6/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1939 - auc: 0.9832 - val_loss: 0.8852 - val_auc: 0.9908\n","Epoch 7/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1063 - auc: 0.9856 - val_loss: 0.8048 - val_auc: 0.9928\n","Epoch 8/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.0127 - auc: 0.9877 - val_loss: 0.7899 - val_auc: 0.9921\n","Epoch 9/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9730 - auc: 0.9889 - val_loss: 0.6945 - val_auc: 0.9942\n","Epoch 10/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9273 - auc: 0.9888 - val_loss: 0.6476 - val_auc: 0.9953\n","Epoch 11/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8838 - auc: 0.9907 - val_loss: 0.6128 - val_auc: 0.9948\n","Epoch 12/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8404 - auc: 0.9912 - val_loss: 0.5992 - val_auc: 0.9954\n","Epoch 13/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8130 - auc: 0.9919 - val_loss: 0.5799 - val_auc: 0.9961\n","Epoch 14/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7888 - auc: 0.9920 - val_loss: 0.5394 - val_auc: 0.9964\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7540 - auc: 0.9927 - val_loss: 0.5196 - val_auc: 0.9971\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7200 - auc: 0.9932 - val_loss: 0.5270 - val_auc: 0.9975\n","Epoch 17/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7465 - auc: 0.9923 - val_loss: 0.4914 - val_auc: 0.9970\n","Epoch 18/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6969 - auc: 0.9939 - val_loss: 0.4871 - val_auc: 0.9974\n","Epoch 19/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6810 - auc: 0.9941 - val_loss: 0.4415 - val_auc: 0.9974\n","Epoch 20/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6243 - auc: 0.9944 - val_loss: 0.4351 - val_auc: 0.9976\n","Epoch 21/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6476 - auc: 0.9939 - val_loss: 0.4231 - val_auc: 0.9981\n","Epoch 22/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6100 - auc: 0.9954 - val_loss: 0.4077 - val_auc: 0.9978\n","Epoch 23/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6352 - auc: 0.9936 - val_loss: 0.4289 - val_auc: 0.9971\n","Epoch 24/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6202 - auc: 0.9943 - val_loss: 0.4267 - val_auc: 0.9968\n","Epoch 25/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5955 - auc: 0.9942 - val_loss: 0.3773 - val_auc: 0.9983\n","Epoch 26/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5797 - auc: 0.9949 - val_loss: 0.3775 - val_auc: 0.9980\n","Epoch 27/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5898 - auc: 0.9952 - val_loss: 0.3701 - val_auc: 0.9976\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5395 - auc: 0.9953 - val_loss: 0.3628 - val_auc: 0.9978\n","Epoch 29/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5718 - auc: 0.9948 - val_loss: 0.3251 - val_auc: 0.9984\n","Epoch 30/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5448 - auc: 0.9957 - val_loss: 0.3555 - val_auc: 0.9981\n","Epoch 31/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5241 - auc: 0.9958 - val_loss: 0.3335 - val_auc: 0.9987\n","Epoch 32/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5113 - auc: 0.9957 - val_loss: 0.3439 - val_auc: 0.9978\n","\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 33/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4527 - auc: 0.9969 - val_loss: 0.2582 - val_auc: 0.9989\n","Epoch 34/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3896 - auc: 0.9979 - val_loss: 0.2542 - val_auc: 0.9986\n","Epoch 35/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3892 - auc: 0.9975 - val_loss: 0.2482 - val_auc: 0.9989\n","Epoch 36/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3826 - auc: 0.9979 - val_loss: 0.2458 - val_auc: 0.9988\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3822 - auc: 0.9975 - val_loss: 0.2355 - val_auc: 0.9990\n","Epoch 38/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3635 - auc: 0.9980 - val_loss: 0.2341 - val_auc: 0.9990\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3660 - auc: 0.9976 - val_loss: 0.2271 - val_auc: 0.9990\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3569 - auc: 0.9979 - val_loss: 0.2259 - val_auc: 0.9990\n","Epoch 41/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3581 - auc: 0.9979 - val_loss: 0.2250 - val_auc: 0.9993\n","Epoch 42/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3653 - auc: 0.9979 - val_loss: 0.2172 - val_auc: 0.9991\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3722 - auc: 0.9975 - val_loss: 0.2208 - val_auc: 0.9989\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3306 - auc: 0.9985 - val_loss: 0.2242 - val_auc: 0.9989\n","Epoch 45/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3455 - auc: 0.9983 - val_loss: 0.2176 - val_auc: 0.9989\n","\n","Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 46/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3474 - auc: 0.9982 - val_loss: 0.2137 - val_auc: 0.9989\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3372 - auc: 0.9983 - val_loss: 0.2116 - val_auc: 0.9989\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3457 - auc: 0.9980 - val_loss: 0.2126 - val_auc: 0.9989\n","Epoch 49/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3373 - auc: 0.9983 - val_loss: 0.2122 - val_auc: 0.9989\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3345 - auc: 0.9984 - val_loss: 0.2128 - val_auc: 0.9989\n","\n","Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3363 - auc: 0.9982 - val_loss: 0.2113 - val_auc: 0.9989\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3327 - auc: 0.9986 - val_loss: 0.2128 - val_auc: 0.9989\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3335 - auc: 0.9982 - val_loss: 0.2128 - val_auc: 0.9989\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3572 - auc: 0.9977 - val_loss: 0.2131 - val_auc: 0.9989\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3232 - auc: 0.9985 - val_loss: 0.2125 - val_auc: 0.9989\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"629bb46197814b599177ffe1b53f29a1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.773427,"end_time":"2020-12-19T21:50:37.314953","exception":false,"start_time":"2020-12-19T21:50:36.541526","status":"completed"},"tags":[],"id":"DmRggyuUwP3S"},"source":["# Submitting"]},{"cell_type":"code","metadata":{"id":"9xxRPhDGwP3S","colab":{"base_uri":"https://localhost:8080/","height":609},"executionInfo":{"status":"ok","timestamp":1613471395656,"user_tz":-540,"elapsed":4271862,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"7e862f11-5aad-4654-89d2-84d8a61bf6cb"},"source":["sample_submssion = pd.read_csv(path + 'sample_submission.csv')\n","sample_submssion.iloc[:,1:] = transformer_test\n","sample_submssion.to_csv(\"transformer.csv\", index = False)\n","sample_submssion"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3125</td>\n","      <td>1.290568e-06</td>\n","      <td>2.869500e-09</td>\n","      <td>2.030623e-07</td>\n","      <td>4.197796e-10</td>\n","      <td>2.253013e-08</td>\n","      <td>8.822967e-10</td>\n","      <td>1.042673e-05</td>\n","      <td>1.970869e-10</td>\n","      <td>5.013131e-10</td>\n","      <td>1.120063e-05</td>\n","      <td>1.263844e-01</td>\n","      <td>6.978915e-03</td>\n","      <td>1.609582e-06</td>\n","      <td>7.844615e-01</td>\n","      <td>1.287721e-04</td>\n","      <td>6.909278e-11</td>\n","      <td>2.384806e-10</td>\n","      <td>3.855866e-07</td>\n","      <td>1.635687e-10</td>\n","      <td>9.426051e-10</td>\n","      <td>6.289107e-07</td>\n","      <td>2.000664e-09</td>\n","      <td>5.074940e-08</td>\n","      <td>1.258584e-06</td>\n","      <td>4.744953e-02</td>\n","      <td>9.916452e-11</td>\n","      <td>2.848666e-08</td>\n","      <td>1.462161e-10</td>\n","      <td>1.488379e-07</td>\n","      <td>4.115700e-07</td>\n","      <td>4.400630e-07</td>\n","      <td>4.757283e-06</td>\n","      <td>2.045285e-08</td>\n","      <td>1.455627e-09</td>\n","      <td>1.163646e-08</td>\n","      <td>3.671322e-10</td>\n","      <td>7.589186e-05</td>\n","      <td>1.097859e-05</td>\n","      <td>1.679651e-07</td>\n","      <td>8.894322e-07</td>\n","      <td>8.833575e-09</td>\n","      <td>8.951837e-09</td>\n","      <td>7.806835e-05</td>\n","      <td>3.058208e-07</td>\n","      <td>4.041567e-08</td>\n","      <td>4.517415e-07</td>\n","      <td>1.340827e-09</td>\n","      <td>1.738505e-07</td>\n","      <td>9.955287e-08</td>\n","      <td>9.893917e-07</td>\n","      <td>6.241727e-10</td>\n","      <td>5.127713e-06</td>\n","      <td>1.080832e-06</td>\n","      <td>5.734582e-08</td>\n","      <td>3.395095e-10</td>\n","      <td>8.817267e-08</td>\n","      <td>1.963295e-09</td>\n","      <td>9.053803e-10</td>\n","      <td>3.438867e-02</td>\n","      <td>2.494924e-08</td>\n","      <td>7.295441e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3126</td>\n","      <td>1.784886e-03</td>\n","      <td>8.311562e-07</td>\n","      <td>2.505620e-07</td>\n","      <td>1.814125e-04</td>\n","      <td>5.865082e-10</td>\n","      <td>2.965130e-08</td>\n","      <td>3.221962e-07</td>\n","      <td>2.920459e-10</td>\n","      <td>1.853208e-06</td>\n","      <td>6.872794e-09</td>\n","      <td>1.989983e-07</td>\n","      <td>2.238871e-09</td>\n","      <td>1.044282e-09</td>\n","      <td>1.961063e-08</td>\n","      <td>8.947366e-08</td>\n","      <td>3.297418e-04</td>\n","      <td>2.726703e-07</td>\n","      <td>8.180625e-10</td>\n","      <td>1.583249e-08</td>\n","      <td>6.157921e-13</td>\n","      <td>3.526151e-10</td>\n","      <td>2.774822e-06</td>\n","      <td>5.452396e-07</td>\n","      <td>8.459625e-05</td>\n","      <td>1.003921e-07</td>\n","      <td>9.712948e-05</td>\n","      <td>9.953672e-01</td>\n","      <td>5.493111e-06</td>\n","      <td>3.460886e-08</td>\n","      <td>9.396947e-08</td>\n","      <td>4.518249e-09</td>\n","      <td>2.524715e-09</td>\n","      <td>1.156189e-05</td>\n","      <td>3.689052e-08</td>\n","      <td>3.813691e-06</td>\n","      <td>4.425703e-05</td>\n","      <td>2.849907e-09</td>\n","      <td>1.460818e-08</td>\n","      <td>1.280352e-08</td>\n","      <td>3.127352e-10</td>\n","      <td>1.301585e-06</td>\n","      <td>1.350160e-11</td>\n","      <td>1.925543e-08</td>\n","      <td>1.062021e-09</td>\n","      <td>1.772396e-10</td>\n","      <td>1.137437e-09</td>\n","      <td>1.191397e-11</td>\n","      <td>4.887929e-04</td>\n","      <td>1.267944e-05</td>\n","      <td>9.022740e-07</td>\n","      <td>8.640297e-06</td>\n","      <td>2.815410e-09</td>\n","      <td>1.649253e-08</td>\n","      <td>5.226534e-10</td>\n","      <td>1.194794e-07</td>\n","      <td>1.089631e-06</td>\n","      <td>1.268560e-10</td>\n","      <td>3.377462e-06</td>\n","      <td>1.456549e-08</td>\n","      <td>1.501085e-07</td>\n","      <td>1.565321e-03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3127</td>\n","      <td>1.596042e-09</td>\n","      <td>2.515256e-03</td>\n","      <td>1.028863e-11</td>\n","      <td>1.171046e-10</td>\n","      <td>2.432430e-10</td>\n","      <td>1.213424e-07</td>\n","      <td>6.890053e-05</td>\n","      <td>2.389400e-05</td>\n","      <td>1.693216e-07</td>\n","      <td>5.823485e-09</td>\n","      <td>2.885670e-07</td>\n","      <td>1.058892e-07</td>\n","      <td>1.312064e-09</td>\n","      <td>3.697806e-08</td>\n","      <td>4.005033e-06</td>\n","      <td>3.851378e-09</td>\n","      <td>2.427317e-07</td>\n","      <td>1.349078e-08</td>\n","      <td>6.581456e-12</td>\n","      <td>2.494359e-10</td>\n","      <td>1.769984e-07</td>\n","      <td>1.810764e-09</td>\n","      <td>5.657420e-11</td>\n","      <td>2.939880e-08</td>\n","      <td>7.637935e-09</td>\n","      <td>2.928422e-09</td>\n","      <td>1.514377e-06</td>\n","      <td>3.472297e-08</td>\n","      <td>3.318153e-09</td>\n","      <td>3.545284e-07</td>\n","      <td>1.060949e-09</td>\n","      <td>8.735122e-09</td>\n","      <td>1.015627e-07</td>\n","      <td>3.422690e-09</td>\n","      <td>5.765028e-09</td>\n","      <td>7.886346e-12</td>\n","      <td>8.785028e-06</td>\n","      <td>4.056519e-05</td>\n","      <td>2.235321e-07</td>\n","      <td>4.474213e-09</td>\n","      <td>5.301296e-05</td>\n","      <td>2.031193e-10</td>\n","      <td>8.793391e-07</td>\n","      <td>6.714400e-07</td>\n","      <td>9.783380e-05</td>\n","      <td>9.959209e-01</td>\n","      <td>5.686528e-09</td>\n","      <td>4.547970e-06</td>\n","      <td>7.812093e-06</td>\n","      <td>4.419408e-06</td>\n","      <td>3.171749e-08</td>\n","      <td>2.208866e-11</td>\n","      <td>3.485151e-08</td>\n","      <td>4.026926e-10</td>\n","      <td>2.386612e-07</td>\n","      <td>2.202156e-12</td>\n","      <td>2.423745e-07</td>\n","      <td>4.368826e-08</td>\n","      <td>1.336178e-07</td>\n","      <td>1.243826e-03</td>\n","      <td>5.170014e-07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3128</td>\n","      <td>3.316110e-02</td>\n","      <td>1.101964e-06</td>\n","      <td>2.200492e-05</td>\n","      <td>1.342759e-05</td>\n","      <td>3.987188e-08</td>\n","      <td>7.199366e-08</td>\n","      <td>1.517369e-08</td>\n","      <td>7.193848e-06</td>\n","      <td>4.512206e-05</td>\n","      <td>4.801694e-09</td>\n","      <td>7.587177e-07</td>\n","      <td>1.067635e-07</td>\n","      <td>7.730357e-09</td>\n","      <td>8.312049e-07</td>\n","      <td>5.898528e-08</td>\n","      <td>1.678366e-08</td>\n","      <td>4.366118e-08</td>\n","      <td>2.280087e-10</td>\n","      <td>4.394300e-06</td>\n","      <td>3.781226e-12</td>\n","      <td>8.713075e-10</td>\n","      <td>6.195582e-05</td>\n","      <td>2.296395e-03</td>\n","      <td>6.734351e-05</td>\n","      <td>2.935690e-06</td>\n","      <td>2.773248e-08</td>\n","      <td>7.586344e-01</td>\n","      <td>1.075665e-07</td>\n","      <td>3.285869e-05</td>\n","      <td>2.862598e-06</td>\n","      <td>6.514408e-07</td>\n","      <td>6.064175e-06</td>\n","      <td>6.194875e-06</td>\n","      <td>3.162048e-03</td>\n","      <td>4.896930e-06</td>\n","      <td>1.320820e-05</td>\n","      <td>3.818685e-08</td>\n","      <td>2.387639e-07</td>\n","      <td>2.419149e-07</td>\n","      <td>4.535355e-07</td>\n","      <td>1.277286e-04</td>\n","      <td>2.614651e-06</td>\n","      <td>6.831480e-04</td>\n","      <td>4.904923e-07</td>\n","      <td>4.116382e-06</td>\n","      <td>1.252718e-07</td>\n","      <td>3.042046e-11</td>\n","      <td>3.818372e-08</td>\n","      <td>2.903498e-04</td>\n","      <td>3.150185e-04</td>\n","      <td>1.673387e-01</td>\n","      <td>2.493809e-10</td>\n","      <td>4.099082e-08</td>\n","      <td>3.391336e-11</td>\n","      <td>3.366302e-07</td>\n","      <td>2.701621e-07</td>\n","      <td>2.588687e-12</td>\n","      <td>5.768284e-03</td>\n","      <td>5.411320e-08</td>\n","      <td>1.786940e-06</td>\n","      <td>2.791761e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3129</td>\n","      <td>5.616270e-05</td>\n","      <td>4.309454e-10</td>\n","      <td>5.727112e-10</td>\n","      <td>1.587894e-07</td>\n","      <td>2.220970e-07</td>\n","      <td>3.452981e-09</td>\n","      <td>1.951687e-09</td>\n","      <td>5.706845e-08</td>\n","      <td>3.210863e-06</td>\n","      <td>5.177764e-06</td>\n","      <td>9.630149e-09</td>\n","      <td>4.805027e-09</td>\n","      <td>2.753156e-09</td>\n","      <td>8.196916e-08</td>\n","      <td>4.519591e-06</td>\n","      <td>1.587353e-04</td>\n","      <td>1.263839e-10</td>\n","      <td>1.288423e-10</td>\n","      <td>8.419382e-09</td>\n","      <td>3.244643e-14</td>\n","      <td>1.056470e-08</td>\n","      <td>1.035551e-07</td>\n","      <td>5.105028e-01</td>\n","      <td>1.199059e-07</td>\n","      <td>5.967081e-06</td>\n","      <td>5.131662e-10</td>\n","      <td>4.831626e-01</td>\n","      <td>3.510719e-10</td>\n","      <td>5.082130e-08</td>\n","      <td>1.632085e-08</td>\n","      <td>7.129507e-07</td>\n","      <td>4.557666e-08</td>\n","      <td>1.479517e-04</td>\n","      <td>2.823207e-08</td>\n","      <td>6.591489e-08</td>\n","      <td>7.540681e-09</td>\n","      <td>1.257789e-07</td>\n","      <td>4.761851e-09</td>\n","      <td>1.177582e-08</td>\n","      <td>6.960234e-10</td>\n","      <td>4.666521e-08</td>\n","      <td>7.649297e-10</td>\n","      <td>7.404046e-10</td>\n","      <td>2.019472e-11</td>\n","      <td>6.185438e-10</td>\n","      <td>5.407819e-11</td>\n","      <td>1.004401e-09</td>\n","      <td>2.830591e-07</td>\n","      <td>1.875002e-04</td>\n","      <td>1.316602e-04</td>\n","      <td>5.478059e-03</td>\n","      <td>4.655859e-11</td>\n","      <td>1.465309e-08</td>\n","      <td>3.441999e-10</td>\n","      <td>1.043771e-10</td>\n","      <td>7.262247e-10</td>\n","      <td>1.455890e-11</td>\n","      <td>1.361162e-04</td>\n","      <td>2.492542e-10</td>\n","      <td>1.181068e-07</td>\n","      <td>1.714294e-05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>777</th>\n","      <td>3902</td>\n","      <td>9.349278e-05</td>\n","      <td>3.742235e-08</td>\n","      <td>8.119013e-09</td>\n","      <td>5.503386e-06</td>\n","      <td>2.141029e-05</td>\n","      <td>7.191209e-08</td>\n","      <td>7.351161e-10</td>\n","      <td>2.508685e-09</td>\n","      <td>3.072708e-06</td>\n","      <td>1.524262e-06</td>\n","      <td>1.585807e-09</td>\n","      <td>1.778340e-07</td>\n","      <td>1.705429e-08</td>\n","      <td>3.595041e-08</td>\n","      <td>2.681252e-06</td>\n","      <td>2.083122e-04</td>\n","      <td>1.648739e-07</td>\n","      <td>3.464836e-07</td>\n","      <td>3.931083e-05</td>\n","      <td>1.380948e-11</td>\n","      <td>1.513845e-09</td>\n","      <td>2.512712e-07</td>\n","      <td>7.994304e-04</td>\n","      <td>4.189594e-08</td>\n","      <td>1.473353e-06</td>\n","      <td>5.697777e-06</td>\n","      <td>9.515572e-01</td>\n","      <td>6.723181e-09</td>\n","      <td>5.029788e-06</td>\n","      <td>3.714475e-07</td>\n","      <td>3.368071e-07</td>\n","      <td>3.447132e-09</td>\n","      <td>2.934167e-05</td>\n","      <td>1.335622e-07</td>\n","      <td>3.650697e-02</td>\n","      <td>4.145341e-06</td>\n","      <td>1.530430e-09</td>\n","      <td>1.777476e-09</td>\n","      <td>3.696659e-09</td>\n","      <td>1.161216e-08</td>\n","      <td>9.370715e-10</td>\n","      <td>2.674475e-08</td>\n","      <td>1.227886e-08</td>\n","      <td>1.989276e-09</td>\n","      <td>7.644035e-10</td>\n","      <td>1.421664e-09</td>\n","      <td>4.566655e-10</td>\n","      <td>2.141538e-06</td>\n","      <td>1.296080e-03</td>\n","      <td>6.768848e-07</td>\n","      <td>2.408183e-06</td>\n","      <td>2.542440e-08</td>\n","      <td>3.336740e-07</td>\n","      <td>2.386910e-08</td>\n","      <td>9.494940e-12</td>\n","      <td>3.591455e-09</td>\n","      <td>3.450051e-10</td>\n","      <td>1.859358e-05</td>\n","      <td>1.352453e-08</td>\n","      <td>2.351399e-09</td>\n","      <td>9.392892e-03</td>\n","    </tr>\n","    <tr>\n","      <th>778</th>\n","      <td>3903</td>\n","      <td>2.305516e-04</td>\n","      <td>7.551714e-08</td>\n","      <td>5.486100e-07</td>\n","      <td>3.893986e-06</td>\n","      <td>5.569029e-09</td>\n","      <td>2.785980e-08</td>\n","      <td>6.004967e-09</td>\n","      <td>6.151442e-12</td>\n","      <td>1.026857e-06</td>\n","      <td>3.725666e-08</td>\n","      <td>2.293459e-09</td>\n","      <td>2.179471e-09</td>\n","      <td>1.153243e-07</td>\n","      <td>1.686884e-08</td>\n","      <td>2.538771e-06</td>\n","      <td>9.552900e-06</td>\n","      <td>2.997247e-09</td>\n","      <td>2.127128e-10</td>\n","      <td>4.933835e-09</td>\n","      <td>1.832180e-12</td>\n","      <td>2.587148e-11</td>\n","      <td>8.552254e-09</td>\n","      <td>1.177265e-06</td>\n","      <td>4.129874e-07</td>\n","      <td>5.832683e-07</td>\n","      <td>1.010739e-05</td>\n","      <td>9.983117e-01</td>\n","      <td>3.150345e-08</td>\n","      <td>6.540476e-07</td>\n","      <td>5.608934e-08</td>\n","      <td>2.372217e-08</td>\n","      <td>2.778746e-09</td>\n","      <td>1.498504e-05</td>\n","      <td>2.344049e-07</td>\n","      <td>2.125342e-05</td>\n","      <td>5.363040e-09</td>\n","      <td>6.948866e-11</td>\n","      <td>7.103023e-09</td>\n","      <td>5.276475e-10</td>\n","      <td>6.187712e-10</td>\n","      <td>7.532970e-10</td>\n","      <td>1.453283e-09</td>\n","      <td>5.840700e-09</td>\n","      <td>3.293702e-10</td>\n","      <td>1.890312e-10</td>\n","      <td>7.553941e-11</td>\n","      <td>8.023355e-12</td>\n","      <td>2.403257e-05</td>\n","      <td>3.127849e-05</td>\n","      <td>4.897997e-06</td>\n","      <td>5.262988e-06</td>\n","      <td>6.791284e-08</td>\n","      <td>3.131883e-07</td>\n","      <td>1.419030e-10</td>\n","      <td>3.785293e-11</td>\n","      <td>3.153212e-07</td>\n","      <td>1.741640e-10</td>\n","      <td>8.273294e-06</td>\n","      <td>3.873333e-09</td>\n","      <td>1.573312e-07</td>\n","      <td>1.315632e-03</td>\n","    </tr>\n","    <tr>\n","      <th>779</th>\n","      <td>3904</td>\n","      <td>4.600823e-05</td>\n","      <td>3.868291e-10</td>\n","      <td>4.633556e-07</td>\n","      <td>2.352704e-02</td>\n","      <td>4.690796e-07</td>\n","      <td>1.164161e-05</td>\n","      <td>6.776942e-09</td>\n","      <td>6.881143e-09</td>\n","      <td>1.022754e-03</td>\n","      <td>2.997440e-01</td>\n","      <td>7.945470e-07</td>\n","      <td>3.811992e-06</td>\n","      <td>1.338976e-06</td>\n","      <td>5.867975e-08</td>\n","      <td>1.450171e-07</td>\n","      <td>7.473002e-04</td>\n","      <td>5.938157e-09</td>\n","      <td>2.992005e-10</td>\n","      <td>1.165717e-07</td>\n","      <td>3.812451e-10</td>\n","      <td>2.199498e-05</td>\n","      <td>1.888530e-04</td>\n","      <td>1.021533e-04</td>\n","      <td>1.094560e-06</td>\n","      <td>6.721676e-04</td>\n","      <td>1.364389e-08</td>\n","      <td>3.030790e-01</td>\n","      <td>2.212213e-08</td>\n","      <td>2.219745e-05</td>\n","      <td>2.364998e-08</td>\n","      <td>1.378575e-01</td>\n","      <td>3.892430e-06</td>\n","      <td>3.338967e-05</td>\n","      <td>1.696317e-09</td>\n","      <td>8.922218e-09</td>\n","      <td>1.754505e-07</td>\n","      <td>1.292498e-03</td>\n","      <td>6.740650e-09</td>\n","      <td>1.065681e-05</td>\n","      <td>1.878811e-08</td>\n","      <td>6.365780e-08</td>\n","      <td>1.538822e-07</td>\n","      <td>3.647172e-07</td>\n","      <td>1.866823e-08</td>\n","      <td>3.165317e-10</td>\n","      <td>2.031818e-10</td>\n","      <td>9.925263e-10</td>\n","      <td>1.510295e-06</td>\n","      <td>2.854989e-04</td>\n","      <td>2.223384e-01</td>\n","      <td>3.384102e-06</td>\n","      <td>4.724802e-06</td>\n","      <td>3.401116e-06</td>\n","      <td>6.273759e-06</td>\n","      <td>1.829198e-09</td>\n","      <td>9.157821e-05</td>\n","      <td>6.998070e-09</td>\n","      <td>3.359119e-06</td>\n","      <td>3.880846e-08</td>\n","      <td>2.531408e-09</td>\n","      <td>8.869496e-03</td>\n","    </tr>\n","    <tr>\n","      <th>780</th>\n","      <td>3905</td>\n","      <td>2.273862e-07</td>\n","      <td>4.705836e-03</td>\n","      <td>2.997196e-09</td>\n","      <td>1.217774e-10</td>\n","      <td>8.627049e-08</td>\n","      <td>1.020947e-09</td>\n","      <td>1.255105e-03</td>\n","      <td>1.620056e-07</td>\n","      <td>5.114099e-08</td>\n","      <td>4.421331e-06</td>\n","      <td>9.156676e-07</td>\n","      <td>1.047996e-05</td>\n","      <td>1.509222e-07</td>\n","      <td>1.736247e-06</td>\n","      <td>5.611339e-07</td>\n","      <td>3.633676e-11</td>\n","      <td>2.183512e-07</td>\n","      <td>3.209347e-06</td>\n","      <td>9.109254e-12</td>\n","      <td>5.901439e-10</td>\n","      <td>1.831548e-08</td>\n","      <td>5.715409e-09</td>\n","      <td>1.880251e-09</td>\n","      <td>5.945345e-10</td>\n","      <td>4.806460e-07</td>\n","      <td>2.787044e-08</td>\n","      <td>1.081432e-05</td>\n","      <td>3.421576e-08</td>\n","      <td>5.932627e-09</td>\n","      <td>1.483303e-05</td>\n","      <td>2.576306e-07</td>\n","      <td>9.146911e-07</td>\n","      <td>5.417390e-05</td>\n","      <td>1.121662e-07</td>\n","      <td>1.360741e-08</td>\n","      <td>7.209857e-12</td>\n","      <td>2.039493e-07</td>\n","      <td>8.176432e-01</td>\n","      <td>4.902778e-04</td>\n","      <td>1.948493e-07</td>\n","      <td>5.338068e-06</td>\n","      <td>8.380695e-08</td>\n","      <td>2.867046e-08</td>\n","      <td>2.290353e-11</td>\n","      <td>9.644281e-08</td>\n","      <td>5.131540e-05</td>\n","      <td>9.103244e-09</td>\n","      <td>1.756748e-01</td>\n","      <td>2.766419e-05</td>\n","      <td>4.007882e-06</td>\n","      <td>5.902470e-10</td>\n","      <td>7.114151e-08</td>\n","      <td>6.673635e-06</td>\n","      <td>6.449899e-09</td>\n","      <td>6.376694e-09</td>\n","      <td>4.427782e-10</td>\n","      <td>1.360791e-10</td>\n","      <td>1.249754e-06</td>\n","      <td>1.117695e-06</td>\n","      <td>2.743516e-05</td>\n","      <td>1.319116e-06</td>\n","    </tr>\n","    <tr>\n","      <th>781</th>\n","      <td>3906</td>\n","      <td>1.496317e-04</td>\n","      <td>5.300416e-07</td>\n","      <td>5.318561e-08</td>\n","      <td>8.493424e-06</td>\n","      <td>8.118133e-07</td>\n","      <td>6.431852e-07</td>\n","      <td>2.263763e-07</td>\n","      <td>1.059470e-08</td>\n","      <td>7.066288e-07</td>\n","      <td>1.262205e-08</td>\n","      <td>4.114436e-04</td>\n","      <td>5.352090e-04</td>\n","      <td>1.144438e-09</td>\n","      <td>4.455576e-05</td>\n","      <td>7.740562e-07</td>\n","      <td>4.015062e-08</td>\n","      <td>2.296609e-08</td>\n","      <td>3.175756e-08</td>\n","      <td>1.019641e-06</td>\n","      <td>8.176454e-13</td>\n","      <td>1.027927e-08</td>\n","      <td>6.928898e-07</td>\n","      <td>7.398282e-04</td>\n","      <td>2.188777e-04</td>\n","      <td>1.772806e-05</td>\n","      <td>9.543242e-07</td>\n","      <td>6.142226e-01</td>\n","      <td>1.078446e-08</td>\n","      <td>1.069848e-07</td>\n","      <td>2.443392e-07</td>\n","      <td>1.045288e-06</td>\n","      <td>9.357482e-07</td>\n","      <td>3.676306e-07</td>\n","      <td>1.615596e-04</td>\n","      <td>2.761041e-04</td>\n","      <td>5.338568e-06</td>\n","      <td>1.167862e-08</td>\n","      <td>3.082537e-09</td>\n","      <td>3.956746e-06</td>\n","      <td>2.578495e-10</td>\n","      <td>8.796957e-09</td>\n","      <td>6.214913e-07</td>\n","      <td>1.708662e-06</td>\n","      <td>2.163680e-06</td>\n","      <td>5.885719e-08</td>\n","      <td>2.079195e-08</td>\n","      <td>2.847403e-09</td>\n","      <td>6.572476e-09</td>\n","      <td>2.467096e-05</td>\n","      <td>9.938292e-06</td>\n","      <td>3.615104e-01</td>\n","      <td>6.305093e-09</td>\n","      <td>2.403321e-07</td>\n","      <td>5.075316e-10</td>\n","      <td>9.702819e-10</td>\n","      <td>2.704781e-08</td>\n","      <td>2.784611e-11</td>\n","      <td>2.152641e-02</td>\n","      <td>1.518515e-06</td>\n","      <td>1.117665e-04</td>\n","      <td>5.889418e-06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>782 rows × 62 columns</p>\n","</div>"],"text/plain":["       id             0             1  ...            58            59            60\n","0    3125  1.290568e-06  2.869500e-09  ...  3.438867e-02  2.494924e-08  7.295441e-07\n","1    3126  1.784886e-03  8.311562e-07  ...  1.456549e-08  1.501085e-07  1.565321e-03\n","2    3127  1.596042e-09  2.515256e-03  ...  1.336178e-07  1.243826e-03  5.170014e-07\n","3    3128  3.316110e-02  1.101964e-06  ...  5.411320e-08  1.786940e-06  2.791761e-02\n","4    3129  5.616270e-05  4.309454e-10  ...  2.492542e-10  1.181068e-07  1.714294e-05\n","..    ...           ...           ...  ...           ...           ...           ...\n","777  3902  9.349278e-05  3.742235e-08  ...  1.352453e-08  2.351399e-09  9.392892e-03\n","778  3903  2.305516e-04  7.551714e-08  ...  3.873333e-09  1.573312e-07  1.315632e-03\n","779  3904  4.600823e-05  3.868291e-10  ...  3.880846e-08  2.531408e-09  8.869496e-03\n","780  3905  2.273862e-07  4.705836e-03  ...  1.117695e-06  2.743516e-05  1.319116e-06\n","781  3906  1.496317e-04  5.300416e-07  ...  1.518515e-06  1.117665e-04  5.889418e-06\n","\n","[782 rows x 62 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"PFDjsQ9D2i0Z","executionInfo":{"status":"ok","timestamp":1613471395909,"user_tz":-540,"elapsed":4270278,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"4228a114-1bbc-4719-e487-d8c5a3956b0c"},"source":["sample_submssion = pd.read_csv(path + 'sample_submission.csv')\r\n","sample_submssion.iloc[:,1:] = transformer_test_shifted\r\n","sample_submssion.to_csv(\"transformer_shifted.csv\", index = False)\r\n","sample_submssion"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3125</td>\n","      <td>1.210503e-06</td>\n","      <td>5.103674e-09</td>\n","      <td>1.758889e-07</td>\n","      <td>2.794935e-10</td>\n","      <td>2.842330e-08</td>\n","      <td>7.101478e-10</td>\n","      <td>1.024310e-05</td>\n","      <td>1.564639e-10</td>\n","      <td>3.072761e-10</td>\n","      <td>1.760240e-05</td>\n","      <td>1.113726e-01</td>\n","      <td>7.353149e-03</td>\n","      <td>1.741414e-06</td>\n","      <td>7.825479e-01</td>\n","      <td>1.689483e-04</td>\n","      <td>7.979151e-11</td>\n","      <td>3.300609e-10</td>\n","      <td>8.159832e-07</td>\n","      <td>2.216265e-10</td>\n","      <td>8.219056e-10</td>\n","      <td>4.513682e-07</td>\n","      <td>2.815428e-09</td>\n","      <td>6.876823e-08</td>\n","      <td>1.306158e-06</td>\n","      <td>6.263956e-02</td>\n","      <td>7.896588e-11</td>\n","      <td>3.660250e-08</td>\n","      <td>1.627239e-10</td>\n","      <td>7.449601e-08</td>\n","      <td>2.370469e-07</td>\n","      <td>4.189752e-07</td>\n","      <td>8.247350e-06</td>\n","      <td>1.369957e-08</td>\n","      <td>2.174678e-09</td>\n","      <td>6.050647e-09</td>\n","      <td>4.703224e-10</td>\n","      <td>6.056242e-05</td>\n","      <td>1.304804e-05</td>\n","      <td>1.126014e-07</td>\n","      <td>4.377106e-07</td>\n","      <td>7.434573e-09</td>\n","      <td>4.803339e-09</td>\n","      <td>5.421645e-05</td>\n","      <td>1.565784e-07</td>\n","      <td>2.402576e-08</td>\n","      <td>3.575959e-07</td>\n","      <td>1.379956e-09</td>\n","      <td>4.221905e-07</td>\n","      <td>1.040666e-07</td>\n","      <td>6.691446e-07</td>\n","      <td>3.926105e-10</td>\n","      <td>5.479303e-06</td>\n","      <td>9.090526e-07</td>\n","      <td>5.645525e-08</td>\n","      <td>1.559263e-10</td>\n","      <td>1.014150e-07</td>\n","      <td>1.060529e-09</td>\n","      <td>1.305513e-09</td>\n","      <td>3.573764e-02</td>\n","      <td>3.043061e-08</td>\n","      <td>8.141018e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3126</td>\n","      <td>6.766380e-03</td>\n","      <td>3.507645e-06</td>\n","      <td>5.189835e-07</td>\n","      <td>5.477252e-04</td>\n","      <td>8.796533e-10</td>\n","      <td>1.100169e-07</td>\n","      <td>5.434371e-07</td>\n","      <td>7.251737e-10</td>\n","      <td>2.687545e-06</td>\n","      <td>1.823711e-08</td>\n","      <td>4.144435e-07</td>\n","      <td>6.847162e-09</td>\n","      <td>1.553884e-09</td>\n","      <td>4.477738e-08</td>\n","      <td>9.359712e-08</td>\n","      <td>4.578484e-04</td>\n","      <td>6.502286e-07</td>\n","      <td>6.741926e-10</td>\n","      <td>3.612985e-08</td>\n","      <td>1.553226e-12</td>\n","      <td>1.093004e-09</td>\n","      <td>1.470763e-05</td>\n","      <td>5.971796e-07</td>\n","      <td>1.663986e-04</td>\n","      <td>1.538917e-07</td>\n","      <td>1.172904e-04</td>\n","      <td>9.877297e-01</td>\n","      <td>8.328065e-06</td>\n","      <td>5.933154e-08</td>\n","      <td>1.965836e-07</td>\n","      <td>1.283084e-08</td>\n","      <td>5.936709e-09</td>\n","      <td>3.076450e-05</td>\n","      <td>5.731653e-08</td>\n","      <td>7.675795e-06</td>\n","      <td>9.616563e-05</td>\n","      <td>7.839805e-09</td>\n","      <td>3.842844e-08</td>\n","      <td>2.618946e-08</td>\n","      <td>3.144758e-10</td>\n","      <td>5.305902e-06</td>\n","      <td>3.067217e-11</td>\n","      <td>2.430439e-08</td>\n","      <td>1.201644e-09</td>\n","      <td>2.015903e-10</td>\n","      <td>2.603957e-09</td>\n","      <td>3.192709e-11</td>\n","      <td>7.464734e-04</td>\n","      <td>9.818777e-06</td>\n","      <td>3.045841e-06</td>\n","      <td>2.251601e-05</td>\n","      <td>5.743210e-09</td>\n","      <td>3.398814e-08</td>\n","      <td>1.747764e-09</td>\n","      <td>1.781359e-07</td>\n","      <td>5.617879e-06</td>\n","      <td>8.159627e-10</td>\n","      <td>3.806204e-06</td>\n","      <td>1.377020e-08</td>\n","      <td>1.683782e-07</td>\n","      <td>3.250182e-03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3127</td>\n","      <td>3.939351e-09</td>\n","      <td>8.171919e-03</td>\n","      <td>3.366476e-11</td>\n","      <td>5.872409e-10</td>\n","      <td>4.771164e-10</td>\n","      <td>1.123621e-07</td>\n","      <td>2.037884e-04</td>\n","      <td>3.430937e-05</td>\n","      <td>3.397406e-07</td>\n","      <td>6.663895e-09</td>\n","      <td>3.463343e-07</td>\n","      <td>9.954608e-08</td>\n","      <td>3.341374e-09</td>\n","      <td>8.831703e-08</td>\n","      <td>6.913990e-06</td>\n","      <td>5.621622e-09</td>\n","      <td>2.269716e-06</td>\n","      <td>1.166202e-07</td>\n","      <td>6.360285e-12</td>\n","      <td>2.226468e-10</td>\n","      <td>1.162579e-07</td>\n","      <td>2.993985e-09</td>\n","      <td>7.668024e-11</td>\n","      <td>8.342138e-08</td>\n","      <td>3.840204e-08</td>\n","      <td>1.120116e-08</td>\n","      <td>7.650077e-06</td>\n","      <td>2.936126e-07</td>\n","      <td>1.143272e-08</td>\n","      <td>6.471717e-07</td>\n","      <td>1.589445e-09</td>\n","      <td>1.230046e-08</td>\n","      <td>2.658495e-07</td>\n","      <td>2.688616e-08</td>\n","      <td>9.611595e-09</td>\n","      <td>2.206844e-11</td>\n","      <td>1.486402e-05</td>\n","      <td>1.270847e-04</td>\n","      <td>3.311030e-07</td>\n","      <td>1.460795e-08</td>\n","      <td>8.111348e-05</td>\n","      <td>1.592537e-10</td>\n","      <td>2.010630e-06</td>\n","      <td>7.589334e-07</td>\n","      <td>1.303407e-04</td>\n","      <td>9.877205e-01</td>\n","      <td>7.753171e-09</td>\n","      <td>2.421746e-05</td>\n","      <td>3.765669e-05</td>\n","      <td>7.619672e-06</td>\n","      <td>8.663988e-08</td>\n","      <td>3.729033e-11</td>\n","      <td>1.020463e-07</td>\n","      <td>4.092623e-10</td>\n","      <td>5.618090e-07</td>\n","      <td>6.330560e-12</td>\n","      <td>1.990519e-07</td>\n","      <td>1.604045e-07</td>\n","      <td>4.564813e-07</td>\n","      <td>3.420504e-03</td>\n","      <td>1.887598e-06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3128</td>\n","      <td>1.936287e-02</td>\n","      <td>6.081655e-07</td>\n","      <td>1.916335e-05</td>\n","      <td>1.085433e-05</td>\n","      <td>3.891061e-08</td>\n","      <td>1.058137e-07</td>\n","      <td>7.135585e-09</td>\n","      <td>3.294193e-06</td>\n","      <td>4.386230e-05</td>\n","      <td>3.266992e-09</td>\n","      <td>1.226672e-06</td>\n","      <td>1.005724e-07</td>\n","      <td>7.610825e-09</td>\n","      <td>3.610843e-07</td>\n","      <td>7.859243e-08</td>\n","      <td>1.812709e-08</td>\n","      <td>2.921665e-08</td>\n","      <td>3.493641e-10</td>\n","      <td>2.335697e-06</td>\n","      <td>3.701006e-12</td>\n","      <td>2.897369e-09</td>\n","      <td>4.891111e-05</td>\n","      <td>1.097574e-03</td>\n","      <td>4.424555e-05</td>\n","      <td>3.359787e-06</td>\n","      <td>2.018388e-08</td>\n","      <td>8.440197e-01</td>\n","      <td>6.737327e-08</td>\n","      <td>3.297722e-05</td>\n","      <td>3.471925e-06</td>\n","      <td>6.874130e-07</td>\n","      <td>4.232907e-06</td>\n","      <td>6.354860e-06</td>\n","      <td>1.475168e-03</td>\n","      <td>1.567802e-05</td>\n","      <td>1.194492e-05</td>\n","      <td>2.868035e-08</td>\n","      <td>1.544115e-07</td>\n","      <td>1.061759e-07</td>\n","      <td>2.971898e-07</td>\n","      <td>6.518509e-05</td>\n","      <td>4.339601e-06</td>\n","      <td>4.984117e-04</td>\n","      <td>4.531529e-07</td>\n","      <td>1.426022e-06</td>\n","      <td>6.782623e-08</td>\n","      <td>5.035641e-11</td>\n","      <td>2.541879e-08</td>\n","      <td>2.425221e-04</td>\n","      <td>4.206630e-04</td>\n","      <td>7.516948e-02</td>\n","      <td>3.829883e-10</td>\n","      <td>5.564762e-08</td>\n","      <td>5.332081e-11</td>\n","      <td>1.433974e-07</td>\n","      <td>5.842832e-07</td>\n","      <td>2.099009e-12</td>\n","      <td>1.404033e-02</td>\n","      <td>3.849723e-08</td>\n","      <td>1.060077e-06</td>\n","      <td>4.334523e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3129</td>\n","      <td>9.531961e-05</td>\n","      <td>3.996713e-10</td>\n","      <td>1.178794e-09</td>\n","      <td>4.257735e-07</td>\n","      <td>6.447102e-07</td>\n","      <td>1.689822e-08</td>\n","      <td>1.569951e-09</td>\n","      <td>1.949512e-07</td>\n","      <td>1.107359e-05</td>\n","      <td>4.632724e-06</td>\n","      <td>1.176838e-08</td>\n","      <td>6.142774e-09</td>\n","      <td>5.059137e-09</td>\n","      <td>7.654535e-08</td>\n","      <td>2.188409e-06</td>\n","      <td>8.426172e-04</td>\n","      <td>2.512438e-10</td>\n","      <td>2.102453e-10</td>\n","      <td>3.447959e-08</td>\n","      <td>2.234685e-13</td>\n","      <td>9.010815e-08</td>\n","      <td>2.685192e-07</td>\n","      <td>5.326591e-01</td>\n","      <td>2.870652e-07</td>\n","      <td>5.401437e-06</td>\n","      <td>1.606982e-09</td>\n","      <td>4.507432e-01</td>\n","      <td>9.266211e-10</td>\n","      <td>2.026048e-07</td>\n","      <td>3.261901e-08</td>\n","      <td>6.814056e-07</td>\n","      <td>5.097654e-08</td>\n","      <td>9.332452e-05</td>\n","      <td>2.199356e-08</td>\n","      <td>1.752578e-07</td>\n","      <td>1.710676e-08</td>\n","      <td>1.728320e-07</td>\n","      <td>1.683409e-08</td>\n","      <td>2.325384e-08</td>\n","      <td>1.581495e-09</td>\n","      <td>1.113572e-07</td>\n","      <td>1.890638e-09</td>\n","      <td>1.758950e-09</td>\n","      <td>8.060829e-11</td>\n","      <td>2.519088e-09</td>\n","      <td>2.157412e-10</td>\n","      <td>2.702132e-09</td>\n","      <td>3.379352e-07</td>\n","      <td>4.007733e-04</td>\n","      <td>1.211936e-03</td>\n","      <td>1.370394e-02</td>\n","      <td>9.155573e-11</td>\n","      <td>1.538156e-08</td>\n","      <td>1.969897e-09</td>\n","      <td>1.750836e-10</td>\n","      <td>4.733727e-09</td>\n","      <td>3.518833e-11</td>\n","      <td>2.077748e-04</td>\n","      <td>1.692637e-10</td>\n","      <td>9.313956e-08</td>\n","      <td>1.465836e-05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>777</th>\n","      <td>3902</td>\n","      <td>3.034979e-04</td>\n","      <td>3.187235e-08</td>\n","      <td>1.340606e-08</td>\n","      <td>1.524764e-05</td>\n","      <td>1.988137e-05</td>\n","      <td>2.496672e-07</td>\n","      <td>7.157655e-10</td>\n","      <td>2.770373e-09</td>\n","      <td>2.050952e-05</td>\n","      <td>3.614754e-06</td>\n","      <td>5.122408e-09</td>\n","      <td>1.931562e-07</td>\n","      <td>1.555301e-07</td>\n","      <td>3.593042e-08</td>\n","      <td>1.567470e-05</td>\n","      <td>9.620300e-04</td>\n","      <td>2.222464e-07</td>\n","      <td>7.526065e-07</td>\n","      <td>2.662539e-04</td>\n","      <td>8.461256e-11</td>\n","      <td>5.568906e-08</td>\n","      <td>3.453784e-06</td>\n","      <td>7.414522e-03</td>\n","      <td>2.227939e-07</td>\n","      <td>3.292818e-06</td>\n","      <td>2.606345e-06</td>\n","      <td>8.515861e-01</td>\n","      <td>5.629259e-09</td>\n","      <td>3.091308e-05</td>\n","      <td>2.489380e-06</td>\n","      <td>6.547702e-07</td>\n","      <td>7.246481e-09</td>\n","      <td>8.849621e-05</td>\n","      <td>1.422631e-06</td>\n","      <td>6.674248e-02</td>\n","      <td>2.765412e-05</td>\n","      <td>1.776228e-08</td>\n","      <td>3.709932e-09</td>\n","      <td>5.428628e-09</td>\n","      <td>6.190164e-08</td>\n","      <td>8.873690e-10</td>\n","      <td>5.211368e-08</td>\n","      <td>4.431202e-08</td>\n","      <td>1.135260e-08</td>\n","      <td>2.197634e-09</td>\n","      <td>3.084774e-09</td>\n","      <td>4.976749e-09</td>\n","      <td>1.674800e-06</td>\n","      <td>7.449533e-03</td>\n","      <td>1.490080e-06</td>\n","      <td>8.624919e-06</td>\n","      <td>6.035607e-08</td>\n","      <td>6.814325e-07</td>\n","      <td>8.089185e-08</td>\n","      <td>9.496521e-12</td>\n","      <td>8.067865e-08</td>\n","      <td>9.574539e-10</td>\n","      <td>7.040818e-05</td>\n","      <td>5.944642e-08</td>\n","      <td>3.000804e-09</td>\n","      <td>6.495437e-02</td>\n","    </tr>\n","    <tr>\n","      <th>778</th>\n","      <td>3903</td>\n","      <td>1.440951e-04</td>\n","      <td>1.892715e-07</td>\n","      <td>1.840877e-07</td>\n","      <td>6.461968e-06</td>\n","      <td>7.194116e-09</td>\n","      <td>2.285909e-08</td>\n","      <td>1.716520e-09</td>\n","      <td>4.657249e-12</td>\n","      <td>6.744476e-07</td>\n","      <td>5.577690e-09</td>\n","      <td>9.351602e-10</td>\n","      <td>8.481754e-10</td>\n","      <td>3.633550e-08</td>\n","      <td>1.343201e-08</td>\n","      <td>5.715989e-07</td>\n","      <td>2.532989e-05</td>\n","      <td>5.957591e-09</td>\n","      <td>2.031991e-10</td>\n","      <td>8.034201e-09</td>\n","      <td>1.954916e-12</td>\n","      <td>4.168034e-11</td>\n","      <td>4.341283e-09</td>\n","      <td>1.518234e-06</td>\n","      <td>1.065031e-06</td>\n","      <td>4.389068e-07</td>\n","      <td>7.823872e-06</td>\n","      <td>9.992440e-01</td>\n","      <td>5.374612e-08</td>\n","      <td>2.037884e-07</td>\n","      <td>3.220488e-08</td>\n","      <td>6.088955e-09</td>\n","      <td>1.777783e-09</td>\n","      <td>5.678105e-06</td>\n","      <td>3.125848e-07</td>\n","      <td>4.297657e-05</td>\n","      <td>1.067894e-08</td>\n","      <td>2.894957e-11</td>\n","      <td>3.385948e-09</td>\n","      <td>1.059633e-09</td>\n","      <td>1.285120e-10</td>\n","      <td>6.575210e-10</td>\n","      <td>2.860270e-09</td>\n","      <td>4.119275e-09</td>\n","      <td>7.277493e-10</td>\n","      <td>2.180666e-10</td>\n","      <td>1.726143e-10</td>\n","      <td>2.361645e-11</td>\n","      <td>7.162127e-06</td>\n","      <td>1.115387e-05</td>\n","      <td>7.550201e-06</td>\n","      <td>4.281828e-06</td>\n","      <td>4.548769e-08</td>\n","      <td>1.787503e-07</td>\n","      <td>1.105893e-10</td>\n","      <td>2.242274e-11</td>\n","      <td>1.958533e-07</td>\n","      <td>4.893490e-10</td>\n","      <td>8.450195e-06</td>\n","      <td>2.201989e-09</td>\n","      <td>5.887360e-08</td>\n","      <td>4.791582e-04</td>\n","    </tr>\n","    <tr>\n","      <th>779</th>\n","      <td>3904</td>\n","      <td>9.009751e-05</td>\n","      <td>6.600102e-10</td>\n","      <td>3.937413e-07</td>\n","      <td>1.691233e-02</td>\n","      <td>4.614890e-07</td>\n","      <td>2.782110e-05</td>\n","      <td>1.958501e-08</td>\n","      <td>2.019560e-08</td>\n","      <td>4.204759e-03</td>\n","      <td>3.252359e-01</td>\n","      <td>9.467828e-07</td>\n","      <td>6.831137e-05</td>\n","      <td>5.830347e-06</td>\n","      <td>1.252015e-07</td>\n","      <td>1.925627e-07</td>\n","      <td>4.289511e-04</td>\n","      <td>6.255601e-09</td>\n","      <td>4.027459e-10</td>\n","      <td>2.445433e-07</td>\n","      <td>2.394212e-09</td>\n","      <td>4.106654e-04</td>\n","      <td>2.702938e-04</td>\n","      <td>9.524622e-05</td>\n","      <td>7.402042e-07</td>\n","      <td>3.457852e-04</td>\n","      <td>1.993831e-08</td>\n","      <td>9.799616e-02</td>\n","      <td>2.045430e-08</td>\n","      <td>2.605556e-05</td>\n","      <td>4.871002e-08</td>\n","      <td>1.429846e-01</td>\n","      <td>4.334568e-06</td>\n","      <td>7.243238e-05</td>\n","      <td>1.421501e-09</td>\n","      <td>8.652953e-09</td>\n","      <td>1.037194e-07</td>\n","      <td>1.184319e-03</td>\n","      <td>1.074072e-08</td>\n","      <td>1.304831e-05</td>\n","      <td>3.349445e-08</td>\n","      <td>1.339182e-07</td>\n","      <td>2.171242e-07</td>\n","      <td>1.317803e-06</td>\n","      <td>6.009887e-08</td>\n","      <td>7.337116e-10</td>\n","      <td>9.668726e-10</td>\n","      <td>2.763975e-09</td>\n","      <td>3.102116e-06</td>\n","      <td>6.812458e-04</td>\n","      <td>3.810847e-01</td>\n","      <td>5.289742e-06</td>\n","      <td>6.027012e-05</td>\n","      <td>1.191650e-05</td>\n","      <td>7.862788e-06</td>\n","      <td>5.664616e-09</td>\n","      <td>1.915359e-04</td>\n","      <td>5.140898e-08</td>\n","      <td>4.628245e-06</td>\n","      <td>2.600165e-08</td>\n","      <td>3.268370e-09</td>\n","      <td>2.756722e-02</td>\n","    </tr>\n","    <tr>\n","      <th>780</th>\n","      <td>3905</td>\n","      <td>4.741074e-07</td>\n","      <td>7.699552e-03</td>\n","      <td>1.885912e-09</td>\n","      <td>1.553126e-10</td>\n","      <td>9.557831e-08</td>\n","      <td>2.178689e-09</td>\n","      <td>1.178009e-03</td>\n","      <td>3.615624e-07</td>\n","      <td>1.716686e-07</td>\n","      <td>4.854308e-06</td>\n","      <td>8.629869e-07</td>\n","      <td>1.159305e-05</td>\n","      <td>1.689873e-07</td>\n","      <td>1.896359e-06</td>\n","      <td>8.020928e-07</td>\n","      <td>4.160784e-11</td>\n","      <td>3.537420e-07</td>\n","      <td>4.666465e-06</td>\n","      <td>1.489563e-11</td>\n","      <td>1.438714e-09</td>\n","      <td>2.619923e-08</td>\n","      <td>5.163896e-09</td>\n","      <td>4.409747e-09</td>\n","      <td>1.116721e-09</td>\n","      <td>6.007574e-07</td>\n","      <td>5.692226e-08</td>\n","      <td>1.349869e-05</td>\n","      <td>5.024919e-08</td>\n","      <td>1.210403e-08</td>\n","      <td>1.524052e-05</td>\n","      <td>3.396262e-07</td>\n","      <td>1.047730e-06</td>\n","      <td>1.187014e-04</td>\n","      <td>2.581587e-07</td>\n","      <td>1.079916e-08</td>\n","      <td>1.467701e-11</td>\n","      <td>1.935360e-07</td>\n","      <td>8.345984e-01</td>\n","      <td>9.108558e-04</td>\n","      <td>4.249923e-07</td>\n","      <td>1.198012e-05</td>\n","      <td>8.747513e-08</td>\n","      <td>9.779635e-08</td>\n","      <td>3.633014e-11</td>\n","      <td>2.378336e-07</td>\n","      <td>8.090130e-05</td>\n","      <td>9.272742e-09</td>\n","      <td>1.552190e-01</td>\n","      <td>6.710279e-05</td>\n","      <td>5.495626e-06</td>\n","      <td>1.165216e-09</td>\n","      <td>6.123657e-08</td>\n","      <td>1.022135e-05</td>\n","      <td>9.107882e-09</td>\n","      <td>1.095327e-08</td>\n","      <td>4.262507e-10</td>\n","      <td>2.709083e-10</td>\n","      <td>1.321584e-06</td>\n","      <td>9.048441e-07</td>\n","      <td>3.766209e-05</td>\n","      <td>1.319634e-06</td>\n","    </tr>\n","    <tr>\n","      <th>781</th>\n","      <td>3906</td>\n","      <td>5.475599e-05</td>\n","      <td>1.086160e-07</td>\n","      <td>7.173970e-07</td>\n","      <td>1.807090e-05</td>\n","      <td>1.384868e-05</td>\n","      <td>3.627745e-06</td>\n","      <td>2.119363e-07</td>\n","      <td>5.651450e-09</td>\n","      <td>1.069527e-06</td>\n","      <td>1.086442e-07</td>\n","      <td>4.320657e-04</td>\n","      <td>1.097018e-02</td>\n","      <td>3.097429e-08</td>\n","      <td>6.740265e-04</td>\n","      <td>3.058296e-05</td>\n","      <td>7.682538e-08</td>\n","      <td>1.826879e-08</td>\n","      <td>5.723743e-08</td>\n","      <td>2.445323e-07</td>\n","      <td>6.453978e-12</td>\n","      <td>1.716374e-08</td>\n","      <td>4.931576e-07</td>\n","      <td>5.417639e-03</td>\n","      <td>4.346603e-04</td>\n","      <td>1.510085e-04</td>\n","      <td>1.320458e-06</td>\n","      <td>6.147517e-01</td>\n","      <td>1.807499e-08</td>\n","      <td>2.344205e-07</td>\n","      <td>1.522829e-06</td>\n","      <td>3.155914e-05</td>\n","      <td>5.630094e-05</td>\n","      <td>6.029913e-06</td>\n","      <td>1.165887e-04</td>\n","      <td>6.544231e-04</td>\n","      <td>4.727741e-06</td>\n","      <td>1.501950e-08</td>\n","      <td>9.113060e-09</td>\n","      <td>1.042707e-05</td>\n","      <td>7.971952e-09</td>\n","      <td>1.635672e-08</td>\n","      <td>2.540841e-06</td>\n","      <td>1.265980e-06</td>\n","      <td>1.886366e-06</td>\n","      <td>5.864233e-08</td>\n","      <td>1.316073e-08</td>\n","      <td>6.390029e-08</td>\n","      <td>8.902237e-08</td>\n","      <td>1.892932e-04</td>\n","      <td>6.289333e-05</td>\n","      <td>3.387066e-01</td>\n","      <td>9.847872e-08</td>\n","      <td>1.264202e-05</td>\n","      <td>2.480246e-09</td>\n","      <td>1.202182e-09</td>\n","      <td>7.756924e-08</td>\n","      <td>3.091054e-10</td>\n","      <td>2.694171e-02</td>\n","      <td>4.439097e-05</td>\n","      <td>1.325841e-04</td>\n","      <td>6.528582e-05</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>782 rows × 62 columns</p>\n","</div>"],"text/plain":["       id             0             1  ...            58            59            60\n","0    3125  1.210503e-06  5.103674e-09  ...  3.573764e-02  3.043061e-08  8.141018e-07\n","1    3126  6.766380e-03  3.507645e-06  ...  1.377020e-08  1.683782e-07  3.250182e-03\n","2    3127  3.939351e-09  8.171919e-03  ...  4.564813e-07  3.420504e-03  1.887598e-06\n","3    3128  1.936287e-02  6.081655e-07  ...  3.849723e-08  1.060077e-06  4.334523e-02\n","4    3129  9.531961e-05  3.996713e-10  ...  1.692637e-10  9.313956e-08  1.465836e-05\n","..    ...           ...           ...  ...           ...           ...           ...\n","777  3902  3.034979e-04  3.187235e-08  ...  5.944642e-08  3.000804e-09  6.495437e-02\n","778  3903  1.440951e-04  1.892715e-07  ...  2.201989e-09  5.887360e-08  4.791582e-04\n","779  3904  9.009751e-05  6.600102e-10  ...  2.600165e-08  3.268370e-09  2.756722e-02\n","780  3905  4.741074e-07  7.699552e-03  ...  9.048441e-07  3.766209e-05  1.319634e-06\n","781  3906  5.475599e-05  1.086160e-07  ...  4.439097e-05  1.325841e-04  6.528582e-05\n","\n","[782 rows x 62 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"A76Wi3ZtwP3S"},"source":["# https://www.kaggle.com/gogo827jz/jane-street-ffill-transformer-baseline\r\n","# https://wikidocs.net/31379\r\n","# https://www.tensorflow.org/tutorials/text/transformer"],"execution_count":null,"outputs":[]}]}